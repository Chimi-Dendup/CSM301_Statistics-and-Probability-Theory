{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3. Regression and Correlation",
      "provenance": [],
      "collapsed_sections": [
        "uL9uB_E9G2A2",
        "P_rUyM_ktNXb",
        "TeluHVpwUXxw",
        "kmH8AkzceKHc",
        "2EZVf612QzFe"
      ],
      "authorship_tag": "ABX9TyMCzkc0swf7c8uNOzoWyVsN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chimi-Dendup/CSM301_Statistics-and-Probability-Theory/blob/main/3_Regression_and_Correlation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!DOCTYPE html>\n",
        "<html >\n",
        "<body>\n",
        "<h1 align=\"center\"> <b>3. Regression and Correlation</b> </h1>\n",
        "<h4 align=\"center\"><i>Prepared by Chimi Dendup</i></h4>\n",
        "</body>\n",
        "</html>"
      ],
      "metadata": {
        "id": "l7HFpokfFLZQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3.1 Overview**"
      ],
      "metadata": {
        "id": "uL9uB_E9G2A2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section, we'll look into curve fitting and try to analyze the fit, which will lead to the building of a model to forecast results or the future in real life using historical records. Regression and classification models are the terms for the method. We'll go over how it was done mathematically, as well as how we built the models using Python programming.\n",
        "\n",
        "By the end of this section, you should be able to\n",
        "\n",
        "**Understand the curve fitting and interpret a fit.**\n",
        "* Define and explain curve fitting.\n",
        "* Use the least square method to find the best fit.\n",
        "* Define, determine and interpret mean square estimation.\n",
        "* Use Python to perform and interpret a best fit.\n",
        "\n",
        "**Understand and implement the correlation and regression to real problems.**\n",
        "* Define and explain correlation and regression lines.\n",
        "* Use the properties of correlation coefficient.\n",
        "* Evaluate the correlation coefficient using Python.\n",
        "* Explain the rank correlation coefficient.\n",
        "* Evaluate the rank correlation coefficient using Python.\n",
        "* Use the properties of regression coefficients.\n",
        "* Distinguish between simple linear, multiple linear, and polynomial regressions.\n",
        "* Construct a simple linear, multiple linear, and polynomial regression model using Python.\n",
        "* Interpret  and perform analysis of regression models using python.\n",
        "* Define, explain, and perform analysis of logistic regression using python.\n",
        "\n"
      ],
      "metadata": {
        "id": "H-oCBvlWpqD3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3.2 Curve Fitting**"
      ],
      "metadata": {
        "id": "P_rUyM_ktNXb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The process of constructing a mathematical relationship or the best fit curve to a group of data points is known as **curve fitting**.\n",
        "$$(OR)$$\n",
        "Let $(x_i,y_i); i=1,2,3,..,n$ be a given set of $n$ pairs of values, $x$ being *independent* and $y$ the *dependent variable*. Here, if possible, **curve fitting** is to find an analytic expression of the form $y=f(x)$.\n",
        "\n",
        "This relationship may be used for:\n",
        " * testing existing mathematical models\n",
        " * establishing new ones\n",
        " * predicting unknown values\n",
        "\n",
        "To do this, we will see two methods, Least square method, and gradient decent method."
      ],
      "metadata": {
        "id": "yaKfLzwq2BeK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.2.1 Least Square Method**"
      ],
      "metadata": {
        "id": "U-Salf3G4dVJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **Least Square Method (LSM)** is a mathematical approach for determining the best fit curve to a set of data points by minimizing the sum of the squares of **residuals**. The discrepancy between the observed and estimated values of a dependent variable is known as **residual**.\n",
        "\n",
        "The Least Squares method can be used to establish both linear and non-linear relationships. Examples of linear **(graph a)** and non-linear **(graph b)** regression are shown in the diagrams below."
      ],
      "metadata": {
        "id": "MYX-VttB46o3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "xXmouIhp8l-_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAx8AAAIgCAYAAADk/9RpAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAAFiUAABYlAUlSJPAAAEjLSURBVHhe7d0N1B1lfSDwJxAw0CghxCVqWlOSbIPgEUpQNGEbFAFdKLhAIxFr3KKWRPeg0grVHMwJLlBZsKt8uMUVEYMcoYCgQMQ1SpBUQg0SFUzQqNGCBJJKxAiBbP7zPkMmk/u+eT9v7r3v73fOvDPPzLz3ztedmf88HzNiy1YJAABgiO2W+wAAAENK8AEAADSF4AMAAGgKwQcAANAUgg8AAKApBB8AAEBTCD4AAICmEHwAAABNIfgAAACaQvABAAA0heADAABoCsEHAADQFIIPAACgKQQfAABAUwg+AACAphixZas83NDVV1+dFi9enFMpzZo1K5144ok5tb158+al9evX51SXBQsWpClTpuQUAAAwXPUYfKxatSp96lOfSpdddlmRLgORRYsWFem6CD6OOeaYboMTAABg+Oqx2FXkWJSBR5g+fXrRj6AEAACgL/pU5+PWW29NkyZN6rEY1fXXX59mz55ddJFTAgAAEHZa5+OWW24pAoqw7777bpcT0pOlS5emyy+/vMc6IjuzZs2aNHHixJwCAADa2U5zPiJwiDoe0Z122mlFjkYEJDszY8aMIpfkkUceyWP6LoIPAACgM/Sp2FUZUNRbtOrJ2LFj8xAAADCc9Rh8RA7HJZdcklNdFc0jJyOKX5XKuh0xb7WOR6Rj3rKSOgAAMLzttM5H/d0d9TocEXxE87pz5swphqsG+o6PJUuWpJkzZ+YUAADQznYafOxKgg8AAOgcfarzAQAA0F+CDwCGRNQDjOK40fQ6AATBB0AbueKKK15o6KORuNGP6fPnz89juhfz/ff//t9zqntR9y/mffzxx/MYAOgfwQdAGzn66KOL/ne+852GwcCdd95Z9KdNm1b0e/Kyl70sbdq0KS1evDiP2dH3v//9otGRmPelL31pHgsA/SP4AGgj0YJgBBYRNHzta1/LY7tErkfZHHq1VcLulAHKypUri34jDz30UNHvTTADADsj+ABoMyeccELRr+d+fPvb3y760fx5b5S5KD0FH8uXLy/6gg8ABoPgA6DNVHM/vvvd7xbj4iWwP/zhD3ud6xGiGNVBBx3UbdGr+Mx///d/L4pcVd/ZFC+R/fCHP1zUA4kuhnsqulVV1klpVGfluuuuK6ZFvy7+7xOf+MQL3xn1UBp9RgRjMb6spxJd1H+JdQFg1xN8ALShMvejvOm/9dZbi35vcz1KBx98cNFvlPvRKNcjAo3rr78+7b333sV3HXnkkUWdkLjh720A0p0//OEP2/VLEexcfvnlRZGy+L5yHeP7LrnkkmK49H/+z/8pxo8dO/aF5XvyySfTY489lucAYFcSfAC0oTL3I2784+Y8goe+5HqU3vCGNxT93gYfkUsyd+7ctHDhwjRnzpx05plnvtBi1n333Vf0B1PkWMT6xbpddNFFxffF91522WVp0qRJxTJGpfhS5P5ETk11+WLeGTNm5DkA2JUEHwBtqsz9iJvzCAr6musRuit6VRa5imnVIleNbuTLdHzGYIvgIj43vqPe2lYZFD3wwANFvxTzaxYYoDUJPgDaVAQF8fQ/bra7y/WIgCKKRFW7CFaqGhW9KnM9yml1UQej+plD5ac//WnRj0Co+n3RRTGsurIY2Mc//vFiPQUhAK1F8AHQxiL4CIcffnjRr4uiUBGAVLsysCg1KnpVzlNOK8UNfRSzijoY1c8cKmVuSixP9fuiK5fxRS96UdEPUcwqcoB+//vfF3VTPvKRjwxpcARA3wg+ADrYRz/60bRo0aLtuqgPUVUvelUtclUt6hTj44Y+RH2K6mcOlVGjRhX9qGdS/b5qd9pppxXzlGLZ/u///b9p1qxZaa+99irWSQAC0BoEHwC8kHMSuR/dFbm65557iv5/+S//pV/1S6qiBaq6yK2oe8UrXlH0f/nLXxb9vohiaGeddVYx3KiIFgDNJ/gAoAgmIpchgo8f/ehHxbh6kauyeFM9SGj0Xo7u7L///kU/goFqfYwoznX33Xfn1DbTp08v+lHHpFH9DfU6ANrL7h+PWnktas2aNWnixIk5BUDdihUrihv5qPtxyCGH5LH9E5/zi1/8oqiwHUWujjvuuDylSwQny5YtKyqB//znP08PP/xwuvHGG4txMe0lL3lJeuMb35jn3rZskavyJ3/yJ8W4/fbbLz300EPF9/zrv/5rETjEZ0TgEa1X/frXv95uXWL+3/zmN8V3LVmypPi8GL733nuLolSRS/PqV7+6aF43ApRojjeml/N89atfLYqTRS5IWT8GgF1HzgdAG6tWth6o1772tXmocQX2aF3rAx/4QBGYlBXAn3766aI+Rlk8qjfe+973FoFG5KBUP6P8/vo6le/2iO8ovzcq0kcwEf936KGHFvNFrkq8XDByb2KeCGgiHf870GJiAAyOEVu2ysMtJ55yzZw5M6cAAIB2JucDAABoCsEHAADQFIIPAACgKQQfAABAUwg+AACAphB8AAAATSH4AAAAmkLwAQAANIXgAwAAaArBBwAA0BSCDwAAoCkEHwCwizz3/Jb0L//2eHrvNQ8X3XXfe7QYB9CpBB8AsIvcsmJduu0H69LTzzxXdN/44YatAchjeSpA5xF8AMAucsfKJ9Mzm7fldDzz3PNpycMbcgqg8wg+AACAphB8AMAuctTUfdIeu2+7FMfwEQfsk1MAnUfwAQC7yF9N2z+98cB906g9diu66ZP3Se+ePj5PBeg8I7ZslYdbzpIlS9LMmTNzCgAAaGdyPgAAgKYQfAAAAE0h+AAAAJpC8AEAADSF4AMAAGgKwQcAANAUgg8AAKApBB8AAEBTCD4AAICmEHwAAABNIfgAAACaQvABAAA0heADAABoCsEHAADQFIIPAACgKQQfAABAUwg+AACAphjU4GPVqlVp9uzZL3Tz58/PUwAAgOFuUIOPa665Js2dOzctWrQoLViwID3yyCPplltuyVMBAIDhbFCDj4ULF6YZM2YUw1OmTEmTJk1K69evL9IAAMDwNmR1PpYuXVrkfEyfPj2PAQAAhrMRW7bKw4Mi6nqUoghWmRPSH0uWLEkzZ87MKQAAoJ0NevBRNW/evDR27NiiOFZ/CD4AAKBzDGlTu8ccc0x68skncwoAWtumTZvSHXfckd7znvekz3zmM3ksAINlUIOPapGrsHz58iLnAwBaXTQP/9KXvjS95S1vSVdddVW68cYb8xQABsugBh+R01F9z0fob5ErAGi2jRs35qGuhlOqaQAGbkjrfAyUOh8ANEtcc4466qic6nLTTTelk046KacAGKghrfMBAO0iWmccPXp0TnW588478xAAg0HwAQBbjRw5Mh199NE51eWuu+7KQwAMBsEHAGTHHntsHuqyevXqogNgcAg+ACA77rjj8tA2cj8ABo/gAwCyiRMnpsmTJ+dUF/U+AAaP4AMAKur1PpYtW5aHABgowQcAVEyfPj0PdXn00UfTmjVrcgqAgRB8AEDFEUcckYe2Wb58eR4CYCAEHwBQEXU+xo8fn1Nd7rnnnjwEwEAIPgCgpp77od4HwOAQfABATb3ex4oVK9KmTZtyCoD+EnwAQE095yMCjwhAABgYwQcA1EybNi2NHDkyp7ooegUwcIIPAKgZNWpUOuSQQ3Kqyw9/+MM8BEB/CT4AoIGDDz44D3VR7Apg4AQfANDAQQcdlIe6PPTQQ3kIgP4SfABAA1OnTs1DXTZu3CgAARggwQcANFAvdhVWrlyZhwDoD8EHADQwceLENHr06JzqIvgAGBjBBwB0o1706oEHHshDAPSH4AMAulEveqXOB8DACD4AoBtavAIYXIIPAOjG5MmT89A2a9asyUMA9JXgAwC6EZXO6wQfAP0n+ACAbgg+AAaX4AMAujFmzJiiqxJ8APSf4AMAelDP/fj5z3+ehwDoK8EHAPSgXulczgdA/wk+AKAH9ZwPwQdA/wk+AKAHr3zlK/NQF8EHQP8JPmCAnnt+S/qXf3s8vfeah4vuuu89WowDOsO4cePy0DaPPvpoHgKgLwQfMEC3rFiXbvvBuvT0M88V3Td+uGFrAPJYngq0u/Hjx+ehbTZt2pSHAOgLwQcM0B0rn0zPbN6W0/HMc8+nJQ9vyCmg3TXK+VD0CqB/BB8A0IPRo0fnoW3kfAD0j+ADBuioqfukPXbf9lOK4SMO2CengHY3YcKEPLSNOh8A/SP4gAH6q2n7pzceuG8atcduRTd98j7p3dN3LCMOtKeRI0emUaNG5VSXDRsUrQToD8EHDNDuu41I7zxi/3TVu6YW3RlHvqwYB3SOeqVzwQdA/wg+AGAnxowZk4e6PPaYFu0A+kPwAQA7UQ8+VDgH6B/BBwD00ebNm/MQAH0h+ACAnZg4cWIe6rJ27do8BEBfCD4AAICmEHwAAABNIfgAgJ0YN25cHuqybt26PARAXwg+AGAn/uiP/igPddm4cWMeAqAvBB8AAEBTCD4AAICmEHwAAABNIfgAAACaQvABAAA0heADAHbid7/7XR7qMmrUqDwEQF8IPgBgJ+rv9Rg/fnweAqAvBB8AAEBT7DT4uPrqq9Ps2bNf6JYuXZqn7GjevHnbzRvdqlWr8lQAAGA46zH4iMDhvvvuS4sWLSq6Y445Jl1++eV5amOzZs16Yf7opkyZkqcAQHvasGFDHuoyevToPARAX/QYfETgcNlll+VUStOnTy/6cjMAGE7qwce4cePyEAB90ac6H4899ljR7yk34/rrr3+hyFUU2QIAAAh9Cj6uu+66ouhVdyKXpCxuNXfu3LR48eJ0yy235KkAAMBw1uvg45JLLkljx45Nc+bMyWN6NmPGjDRp0qT0yCOP5DEA0J7qTe2OGTMmDwHQF70KPiLwiCBi4cKFeUzvRcACAO1s48aNeajLPvvsk4cA6IudBh/z589P69ev367ieVVZtyOKV1XreEQ6ApaykjoAADC89Rh8xDs9IoCIrqxEHl3khNSdeOKJRR2Pcp6oeL5gwQJN7QIAAIURW7bKwy1nyZIlaebMmTkFALvGXnvtlTZt2pRTKV166aXprLPOyikAeqtPrV0BwHBUDTyCCucA/SP4AIAe1AMPAPpP8AEAPVi7dm0e2mbixIl5CIC+EHwAQA8aBR8TJkzIQwD0heADAHqwZs2aPLSN4AOgfwQfANCDes5HVDYfNWpUTgHQF4IPAOjBr371qzzURa4HQP8JPgCgB/WcD8EHQP8JPgCgB4IPgMEj+ACAHtSDj1e84hV5CIC+EnwAQDfiBYPr1q3LqS7e8QHQf4IPAOhGo3d8jB8/Pg8B0FeCDwDoRqPgQ50PgP4TfABAN7xgEGBwCT4AoBv1nI/Ro0cXLxkEoH8EHwC0nNu/tyq966Kb0pvP/nw6/YJ/Sbfd+3Ce0lxeMAgwuAQfALSUL931QLr8q/en3+/98vSf/uzw9MzoV6TP3flguvrO7+c5mqee86GyOcDACD4AaCk33v2j9Ecv/89pz71enEaM2K3oj9p/Urp56Y/zHM1TDz40swswMIIPAFrf1iBkV6gHH4pdAQyM4AOAlvKXb5iann5sdXp20++KdPSffnRVOvbwKUW6WR599NEdXjD4yle+Mg8B0B+CDwBaypxjD01//caD0pYnf5p+/aN7i/6sGVPSe48/LM/RHMuXL89D2xxyyCF5CID+GLFlqzzccpYsWZJmzpyZUwDQPBdeeGE699xzcyqlkSNHpqeeeiqNGjUqjwGgr+R8AEAD999/fx7qcvDBBws8AAZI8AEADaxYsSIPdYngA4CBEXwAQM3GjRvT6tWrc6rLYYc1t84JQCcSfABATT3XI8j5ABg4wQcA1DQKPqZNm5aHAOgvwQcA1DzwwAN5qEu8XHDMmDE5BUB/CT4AoKae8yHXA2BwCD4AoGLz5s1p5cqVOdXlNa95TR4CYCAEHwBQEYHHpk2bcqqLN5sDDA7BBwBU1HM9guADYHAIPgCgov5m86hoPnHixJwCYCAEHwBQUc/5kOsBMHgEHwBQsXz58jzURfABMHgEHwCQrV27Nm3YsCGnuhx22GF5CICBEnwAQLZ06dI8tM3BBx+chwAYKMEHAGTf/va381CX0aNHt23w8dzzz6drFq9IJ85fVHSfve2+YhzAriT4AIDsrrvuykNdjj766DRy5Micai9fuusH6YZ7VqW9XjY17f3yA9Pt96/dGoBsX58FoNkEHwCw1Zo1a9Lq1atzqsub3vSmPNR+brz7R2nv/SelkXuOSrvv8aK01/4HpK8v+0meCrBrCD4AYKt6rkeInI92NmKEyzzQWpyVAGCrb37zm3moy4QJE9LUqVNzqv289XVT0tO/+Vl6bvOzRff7x3+ejjr0gDwVYNcQfADAVkuWLMlDXdo91+OMtx6Wjjl0QnrqFw8W3ZFTx6WzTj4iTwXYNUZs2SoPt5y4EMycOTOnAGBorFixIh166KE51eWLX/xiOv3003MKgMEg5wOAYa8T63sAtCLBBwDDXr2+R7zbY/z48TkFwGARfAAwrG3evHmHN5vL9QAYGoIPAIa1CDw2btyYU12OPfbYPATAYBJ8ADCs1Vu5ijeaz5gxI6cAGEyCDwCGtXp9jwg8Ro8enVMADCbBBwDDVhS3WrZsWU51+Yu/+Is8BMBgE3wAMGxFkauocF513HHH5SEABpvgA4Bhq17kKopbTZs2LacAGGyCDwCGrfrLBaOJ3ahwDsDQGNTgY9WqVWn27NkvdJdcckmeAgCtZfXq1WnlypU51eVNb3pTHgJgKAxq8HHNNdekuXPnpkWLFqUFCxak5cuXp1tuuSVPBYDW8eUvfzkPbXPSSSflIQCGwqAGHwsXLnyhbfQpU6akSZMmpfXr1xdpAGglN954Yx7qEtevCRMm5BQAQ2FI63w8+eSTad99980pAGgNK1asKLqqk08+OQ8BMFSGLPi4+uqri/6JJ55Y9AGgVdRzPcIpp5yShwAYKkMSfCxdujQtXrw4nXXWWXkMALSOen0PRa4AmmPQg48IPC6//PKi4nnU+wCAVhLFraKlq6p3vetdeQiAoTSowUe0bBWBR7R0VVY8B4BWUi9yFe/10MoVQHOM2LJVHh6wefPmNWzdKpre7Y8lS5akmTNn5hQADFzkyldzPuLFgt/4xjdyCoChNKjBx2ATfAAwmKLI1aGHHppTXf75n/85nXHGGTkFwFAa0qZ2AaCVfOELX8hDXRS5AmguwQcAw8YNN9yQh7ocf/zxady4cTkFwFATfAAwLERrjGvXrs2pLl4sCNBcgg8AhoV6K1ejRo1S5AqgyQQfAAwL9SJXxx13XBo9enROAdAMgg8AOp4iVwCtQfABQMerF7mKHI9TTjklpwBoFsEHAB1t06ZN6dprr82pLlHXI+p8ANBcgg8AOloEHuvWrcupLrNmzcpDADST4AOAjnbZZZfloS4TJkwoKpsD0HyCDwA6VlQ0X7FiRU51mTdvXvFmcwCaT/ABQMeq53pEPY8zzjgjpwBoNsEHAB3p0Ucf3eHdHtHC1bhx43IKgGYTfADQkSLXY/PmzTnVJYpcAbDrCD4A6DjRvO5VV12VU12mTZuWjjjiiJwCYFcQfADQcW6++eai2FXV+973vjwEwK4i+ACg4/zTP/1THuoS9TxOP/30nAJgVxF8ANBRli9fnpYtW5ZTXebMmeON5gAtQPABQEep53oEFc0BWoPgA4COsW7duh2a1z3++OPTxIkTcwqAXUnwAUDHiBauoqWrKhXNAVqH4AOAjhDv9Ki/0Xzy5MlFzgcArUHwAUBHiOZ1165dm1Nd5HoAtBbBBwAdoV7RPFq3OuOMM3IKgFYg+ACg7S1ZsiQtXbo0p7rEez3GjBmTUwC0AsEHAG1vwYIFeWgbzesCtB7BBwBtLXI9oqs66aST0iGHHJJTALQKwQcAba1Rrsd5552XhwBoJYIPANqWXA+A9iL4AKBtyfUAaC+CDwDaklwPgPYj+ACgLcn1AGg/gg8A2o5cD4D2JPgAoO3I9QBoT4IPANqKXA+A9iX4AKCtyPUAaF+CDwDahlwPgPYm+AAYJr7zwJr0jgtuLLoYbkdyPQDam+ADYBh4+Jfr0ie/ck96dvSEovvHr3w3Pfizx/LU9iDXA6D9CT4AhoEb7v5R2uPF+6c993px0e2xz8vSdd98ME9tD3I9ANqf4ANgGHhg9WNpzxePzamURo3eNz30y8dzqvXJ9QDoDIIPgGFg/W83ppF7jsqplHbfY8+04amnc6q1bd68OX3gAx/IqW3kegC0H8EHwDCw70tGp+ee/UNOpfTc5mfTmBfvnVOt7TOf+UxauXJlTnV5+9vfLtcDoA0JPgCGgYNeOS5temp9TqX0h99tSFMm7JdTrevRRx/doa7H6NGj0yc/+cmcAqCdCD4AhoG3v/HV6dnfPpqe3fR02vzMprR5w6/TyUe+Kk9tXfPnz08bNmzIqS4f+chH0oQJE3IKgHYi+AAYBv7sj8elvz/1Den5Jx5Jzz2+Kp1x3KHptVNb+wZ+2bJl6aqrrsqpLpMnT05nn312TgHQbkZs2SoPt5xo2WTmzJk5BcBwcvjhh6fly5fnVJfbb789HXfccTkFQLuR8wFAy4kcj3rgcfzxxws8ANqc4AOAlhJ1PM4999yc6jJq1Kh06aWX5hQA7UrwAUBLicBj3bp1OdUl6nlEfQ8A2pvgA4CWEe/zqFcynzhxYvroRz+aUwC0M8EHAC3jzDPPLN5oXnXBBRcUxa4AaH+CDwBawrXXXpuWLl2aU12OPvro4m3mAHSGXjW1e8stt6Trr78+TZs2LX3oQx/KY3c0b968tH79tjfohngz7ZQpU3KqbzS1CzA8bNy4sbhWxBvNSyNHjkwPPvhgmjp1ah4DQLvbac5HBBSPPPJIEXj0xqxZs9KiRYte6PobeAAwfHziE5/YLvAI73//+wUeAB1mp8HHZZdd1mNuBwAMxEMPPZQuvvjinOoyfvz4dN555+UUAJ1i0Ot8RPGs2bNnF93VV1+dxwJAY40qmX/yk59MY8aMySkAOsWgBh+RS1IWt5o7d25avHhxUV8EABr5zGc+U9TvqzriiCPS6aefnlMAdJIha+1qxowZadKkSUV9EQCoi+JW9TeZRyXzT3/60zkFQKcZsuCjNHbs2DwEAF2imNW73/3uopWrqniTeW8bOAGg/Qw4+CjrdkTxqmodj0hHrsf06dPzGADocuGFF6Zly5blVJdDDjkkLVy4MKd2rdu/tyq966Kb0pvP/nw6/YJ/Sbfd+3CeAsBA7PQ9H43e3VF930cEH8ccc0yaM2dOMVw1kHd8BO/5AOg8K1asSIcffvh2lczjDeb33ntvEYDsal+664H05SU/Tnvt/6dpj1F/lJ7d9Lv07BO/TCe+flKac+yheS4A+qNXLxncVQQfAJ1l06ZNReCxcuXKPKZLtG4VRa5awX8777q05/5/lkbuOSqPSem5Z/+Qfv/rH6ebF27/kA2AvhnyOh8AUJo/f/4OgUc8ZDrrrLNyqkWNcLkEGAzOpgA0ReRm118mOHr06PT5z3++aOWqVfzlG6ampx9bXRS3CtF/+tFV6djD+1+MGIAugg8Ahly0ahWtW9VdeumlaeLEiTnVGqJex1+/8aC05cmfpl//6N6iP2vGlPTe4w/LcwDQX+p8ADDkIvCotogYjj/++HTrrbfmFADDgZwPAIbUbbfdtkPgMW7cuKK4FQDDi+ADgCGzbt26hsWtrrjiiiIAAWB4EXwAMGTOPPPMIgCpivdCnXLKKTkFwHAi+ABgSERRqxtuuCGnukTl8qhkDsDwJPgAYNCtWbMmffCDH8ypbaKex5gxY3IKgOFG8AHAoIpmdd/2trelDRs25DFd4kWCWjAEGN4EHwAMqqjnsWLFipzqMnXq1HTBBRfkFADDleADgEETbzC/9tprc6pLvMX8uuuuS6NGjcpjABiuBB8ADIq77rornXvuuTm1TTSre8ghh+QUAMOZ4AOAAYsK5qeddlravHlzHtPl7LPPTqeffnpOATDcCT4AGJCoYH7CCSfs8D6Po48+Wj0PALYj+ABgQOIN5itXrsypLvE+j6jnMXLkyDwGAAQfAAzA+eefv8OLBKOC+U033ZTGjRuXxwBAF8EHAP1yxx13pAULFuTUNiqYA9AdwQcAfbZ69eqGFczPOeccFcwB6JbgA4A+6e4N5scdd1xauHBhTgHAjgQfAPRJ5HjUK5hPnjxZBXMAdkrwAUCvffzjH0+33XZbTnUpK5iPGTMmjwGAxgQfAPRKBB2NKph//vOfTwcffHBOAUD3BB8A7NTSpUuL4lZ1H/vYx9Ipp5ySUwDQM8EHAD166KGH0qmnnlpUNK+KCubnnXdeTgHAzgk+AOjWmjVr0lFHHZUeffTRPKbL1KlTVTAHoM8EHwA0FAHHW97ylh0Cj/Hjx6tgDkC/jNiyVR5uOUuWLEkzZ87MKRg+Hv7lunTD3T9KD6x+LK3/7ca070tGp4MnvjTNOurg9Gd/PC7PRad57vnn05fu+kG6ceu+D2993ZR0xlsPS7vv1vznRFHE6vWvf/0OTepGwHHvvfcWOR8A0FdyPqDFfOeBNensz96Z7v/lM2m3cZPS/lNfV/QfeOz59OHPLi6m05ki8LjhnlVpr5dNTXu//MB0+/1r02dvW56nNk8EHpHjUQ88okndW2+9VeABQL8JPqDFfPbr96e99p+c9t7v5WnknqOKcdHfa9/x6Y/GT0mfvvlfi3F0nsjx2Hv/ScX+3n2PF209Dg5IX1/2kzy1OTZv3lxULo/WraqibkcEHjNmzMhjAKDvBB/QYp55ZnMaMaLxT3PEbrvnITpVd/u+GSLwiOZ077jjjjymSwQeUblcMVgABkrwAS1m7l8enjb++0/S79Y/lp7b/GwxLvpP/8fj6el/fzi98+jXFOPoPFHH4+nf/KzY39H9/vGfp6MOPSBPHXof/OAH0w033JBT21xxxRXe5QHAoFDhHFrQgz97LC365oPp4V8+njY89XQa8+K905QJ+6WTj3xVeu3UCXkuOk1UOL/ytvvT7cseLtIReJx18hFNqXD+d3/3d+niiy/OqW0uvfTSdNZZZ+UUAAyM4ANgmPvUpz5V5HrUnXPOOemCCy7IKQAYOMWuAIaxK6+8smHgEbkdAg8ABpvgA2CYivodH/jAB3Jqm6jfEcWtAGCwCT4AhqEIPKJlq2jhquqkk04qWrYCgKEg+AAYZroLPOIdHl/84heLpnUBYCgIPgCGkahcHi8RrAce06ZNS7fffnvxFnMAGCqCD4BhYv78+Q0rl0+dOrV4e7nAA4ChJvgA6HCRyxFBx/nnn5/HbBNFrb71rW+l8ePH5zEAMHQEHwAdLAKPqN8Rxa3qjj766KKolcADgGYRfAB0qI0bN6YTTjihqGBeF83pDrSOR7yR/ZrFK9KJ8xcV3Wdvu68YBwDdEXwAdKB169alt7zlLemOO+7IY7aJFwhGc7oDbdXqS3f9IN1wz6q018umpr1ffmC6/f61WwOQ5XkqAOxI8AHQYR599NF05JFHpqVLl+Yx25x33nnFCwQHozndG+/+Udp7/0lp5J6j0u57vCjttf8B6evLfpKnAsCOBB8AHeShhx5Kr3/964t+VQQbEXR8/OMfz2MGx4gRLiMA9J6rBkCHWLFiRTrqqKPSmjVr8pguEXhEMasobjWY3vq6Kenp3/wsPbf52aL7/eM/T0cdekCeCgA7EnwAdIAoYhVFraLIVVVUKI+K5VHBfLCd8dbD0jGHTkhP/eLBojty6rh01slH5KkAsKMRW7bKwy1nyZIlaebMmTkFQCPRmtU73/nOtGnTpjymy7hx49JNN91UvMsDAFqBnA+ANhZ1OOI9HvXAI97dcffddws8AGgpgg+ANlQ2pbtgwYLiRYJVU6dOTffdd1/RB4BWIvgAaDPLly9Phx9+eMN3eBxxxBHpW9/6VpowYUIeAwCtQ/AB0EauuuqqomJ5vUWrEJXKv/GNbxRFrgCgFQ1J8DF79uyiA2BwbNy4Mb373e9O73nPe3ao3xFN6X7yk59MX/nKV4rWrQCgVQ1q8HH11VcXQcfcuXPzGAAGavXq1UVuR5xj6yKXI3I7zj777DwGAFrXoAYfc+bMSYsWLcopAAbq5ptvLup3xAsE66Ilq+9///uaJAegbajzAdCCogWrc889N73tbW9LGzZsyGO3ibeVR8Vy9TsAaCeCD4AWE28pj2Z0L7zwwjxmm6jTcd1116VLL720qOsBAO1E8AHQQpYuXVoUs7rrrrvymG3ivR333ntvevvb357HAEB7EXwAtIhPfepT6aijjkpr167NY7aJZnTjxYEHH3xwHgMA7UfwAbCLRbBxwgknpA9+8IM7vK1cM7oAdJIRW7bKwwMWzUAuXrw4p7bpbwtYS5Ys0YoL0NHivBlBR6NK5VGZPOp3OA8C0CkGNfgYbIIPoFNFpfJ4YeBtt92Wx2wvmtGN3A6tWQHQSRS7AmiyG264Ib361a/uNvDQjC4AnUrwAdAk69atS6eeemrRxXDdxIkTi6BDM7oAdCrBB0ATRG7HgQceWPQbef/7358efPBBRU0B6GiCD4AhtHr16uKFgTvL7fj0pz+tNSsAOp7gA2AIbNq0Kc2fP7+o23HHHXfksduT2wHAcCP4ABhkN998c1HE6vzzzy+CkDq5HQAMV4IPgEFSFrF629veltasWZPHbhOVyOV2ADCcCT4ABqg3RayOOOKIdO+998rtAGBYE3wA9NPmzZvTlVdemf70T/+02yJW48aNS//8z/9cBB7Tpk3LYwFgeBJ8APTD1VdfXdTrOPPMM4u3lddFEau//du/TatWrUpnnHFGeu7559M1i1ekE+cvKrrP3nZfMQ4AhhPBB0AfRGXyQw89NL373e8u6ng0UhaxuuKKK9KYMWOKcV+66wfphntWpb1eNjXt/fID0+33r90agCwvpgHAcCH4AOiFJUuWpNe//vVFZfIVK1bksdsbP358t0Wsbrz7R2nv/SelkXuOSrvv8aK01/4HpK8v+0meCgDDg+ADoAcRdBx11FFFt2zZsjx2e5G7sXDhwvSzn/2sKGLVnREjnHIBGN5cCQFqoiL5DTfckA4//PAi6IgApJFRo0alc845pwg6PvaxjxXp7rz1dVPS07/5WXpu87NF9/vHf56OOvSAPBUAhgfBB0C2cePG9KlPfaqoSH7qqaem5csb18koK5NH0HHBBRe8UK+jJ2e89bB0zKET0lO/eLDojpw6Lp118hF5KgAMDyO2bJWHW048bfQiLmCoRWtV//RP/1Q0m7thw4Y8trE5c+akj370o2ny5Ml5DADQW3I+YBeI90FE0R52rajD8c53vrN4T8eFF17YbeAROR2nnHJK+v73v58+//nPCzwAoJ8EH7ALnHvuuUXRniji0+jFdAydyOW4+OKLi+0frVdde+213e6DqMNx1llnpR//+MfpK1/5SjrkkEPyFACGynPPb0n/8m+Pp/de83DRXfe9R4txdAbFrqDJ4uY3nrSXN7xRX+D9739/mjdvXtFUK4MvcpnuuOOO9IUvfKF4T8fOcp1iP8T+iP3Sm/ocAAyeCDxu+8G69MzmrlvUPXffLb3xwDHp9CNcIzuBnA9ososuumi7J+1R1Of8888vApL3vOc96aGHHspTGKh4CWDkMsW2PeGEE4oWrHoKPKZOnVq8p6NsvUrgAdB8d6x88oXAIzzz3PNpycM918ejfcj5gCaKoCNuhCP3oydHH310esc73lHUMxg9enQeS2/ECwAjd+OWW27p9mWAVVGfI7b3+973vnTSSSflsQDsKlHU6ulnnsupLqP22C1d9a6pOUU7E3xAk0UAEq0qRetKa9asyWMbizoHEYBEIBI3yHGjvCt95ds/TLct+0l6fP1T6T/t++J03OGT06kzD0q777ZrM1GjSdwINr785S8XuR29MXHixPQ3f/M3RetVEyZMyGMB2NWijsfiH25Izz73fJHeY/fd0vTJ+6QzjnxZkaa9CT5gF4niP3Gz/L/+1//q1RP6qIfw9re/Pb3rXe/aJRWfz7nqrvTjX/1HetHYCWnknnunzc88nf7w5No0cb+90iVzj2tqABIBXLRUFQFHFKVau3ZtntKzMpiLoMO5BaA1ReXyRd/7Tfr2w+uL9BEH7JPePX381uvMiCJNexN8QAu46667irog0e+NCESOO+649KY3vanojxs3Lk8ZGpHjce2Sh9KLX3FgHrPN7/79J+ltr5uY/vqYoQuIymAjzgnf/va3i+FqvZmdmTZtWhFwRPCmHgcA7DqCD2ghK1euTJ/73OeKHJGd1QupipvrKJZ17LHHpiOOOKJ4wj+Y3nXRTen3e7887bnXi/OYbZ75/e/Si373y/TFc/5bHjNw8abxKErV32AjzJgxI5144olFPQ7v5QCA1iD4gBYURbIiF+RLX/pSUayoLzfeEXgcfPDBRdGs17zmNUU/uoFUXH/LOV9I+/7pn6fddt89j9lmy5bn028evi994+J35zF9E3U0IuiKomcPPPBAMdzbehtVUR8mzhcnn3xyOv7449XjAIAWJPiAFhe5ABGARCDS22JZjUQzshGUHHTQQUVl67g5L7udBSY95Xw8u+l3aeRvf56+9A+n5DHbi+WPOhllF5Xsf/WrXxVBRnQxvb9iuSPHJ3I4IuAY6uJnAMDACD6gjURRrHhZ3je/+c0iEOlL0ayexE18NRgJUTdin332KYYf/Olj6Se/+X168cv/c5EOf3hqfXr2D0+nZ3/3ZHrl2Bell43eVhEwgoxYtujHe0wGSyxnFKf6i7/4i+LcEMXNdnULYABA7wk+oI1FUaUIQiIYid9LX+tFtDrBBgB0FsEHdIiyRaioqB11JyIwibel9/RG71YSRaaibkoUDSvrqsSwYAMAOofgAzpYBCTVytzRjzoXURxqVymLdkW9k8MOO6yoixI5GtF8MADQ2QQfMEyVQUjZRSXw6K9bt66YHv1qZfAYLqeFqBNSfWdGBBOlGB8Bxite8YrtKrdX5wEAhh/BBwAA0BS75T4AAMCQEnwAAABNIfgAAACaQvABAAA0heADAABoCsEHAADQFIIPAACgKQQfAABAUwg+AACAphB8AAAATSH4AAAAmkLwAQAANIXgAwAAaArBBwAA0BSCDwAAoCkEHwAAQFMIPgAAgKYQfAAAAE0h+AAAAJpC8AEAADTFiC1b5eGGVq1alc4777ycSmnatGnpQx/6UE5tb968eWn9+vU51WXBggVpypQpOdU3S5YsSTNnzswpAACgne00+Jg9e3Y65phj0pw5cxqmqyL4iGknnnhiHjMwgg8AAOgcPRa7uuWWW9K+++67XaARwcV9992XUwAAAL3TY/ARRajGjh2bU10iGKkXraq6/vrri9yR6K6++uo8FgAAGO76XOF8v/32y0M7uuyyy9KiRYuKbu7cuWnx4sVF7gkAAECfg48nnngiD/VsxowZadKkSemRRx7JYwAAgOGsx+Ajilg9+eSTOdUlilxFUNFb9WJbAADA8NRj8PGqV72qCDaqRaeiKFU0t1sq63bEPNU6HpGOXI/p06fnMQAAwHC206Z2ly5dmi6//PKc6mrtqtr6VbXp3RiuGsg7PoKmdgEAoHPsNPjYlQQfAADQOfpc4RwAAKA/BB8AAEBTCD4AAICmEHwAAABNIfgAAACaQvABAAA0heADAABoCsEHAADQFIIPAACgKQQfAABAUwg+AACAphB8AAAATSH4AAAAmkLwAQAANIXgAwAAaArBBwAA0BSCDwAAoCkEHwAAQFMIPgAAgKYQfAAAAE0h+AAAAJpC8AFAS3nu+efTNYtXpBPnLyq6z952XzEOgPYn+ACgpXzprh+kG+5ZlfZ62dS098sPTLffv3ZrALI8TwWgnQk+AGgpN979o7T3/pPSyD1Hpd33eFHaa/8D0teX/SRPBaCdCT4AaDkjRrg8AXQiZ3cAWspbXzclPf2bn6XnNj9bdL9//OfpqEMPyFMBaGeCDwBayhlvPSwdc+iE9NQvHiy6I6eOS2edfESeCkA7G7FlqzzccpYsWZJmzpyZUwAAQDuT8wEAADSF4AMAAGgKwQcAANAUgg8AAKApBB8AAEBTCD4AAICmEHwAAABNIfgAAACaQvABAAA0heADAABoCsEHAADQFIIPAACgKQQfAABAUwg+AACAphB8AAAATSH4AAAAmkLwAQAANIXgAwAAaArBBwAA0BSCDwAAoCkEHwAAQFMIPgAAgKYQfAAAAE0h+AAAAJpC8AEAADTFiC1b5eFBMX/+/PTII4/kVEqLFi3KQ323ZMmSNHPmzJwCAADa2aDmfFxyySXpySefLAKO6KZNm5bmzZuXpwIAAMPZoAYfy5cvT6eddlpOpXTCCSek9evXp6VLl+YxAADAcDVowceqVauK/v7771/0w5QpU4r+E088UfQBAIDha8grnO+77755CAAAGM4GrcJ55Hycd955acGCBS/keITZs2enWbNmpRNPPDGP6b0VK1akDRs25BQAALArTJw4segGalBbu4pAY+7cuWnGjBlFuruABAAAGH4GtdjVpEmT0p133plTKd16663FOIEHAAAw6O/5iKZ1o4WrEPU9LrvssmIYAAAY3gY9+AAAAGhkyFu7AgAACIIPAACgKQQfAABAUwg+AACAphB8AAAATSH4AAAAmkLwAQAANIXgAwAAaArBBwAA0BSCDwAAoClGbNkqD7eMVatWpfPOOy+nUpo2bVr60Ic+lFO0q6VLl6bLL788p1I65phj0pw5c3Jqe7Nnz85D2yxatCgP0c7K3/e+++6bLrvssjyWdlf+vidNmpQWLlyYx+5o/vz56ZFHHsmpLnPnzk0zZszIKdqR63Zn6st1+5JLLknLly/PqS6zZs1KJ554Yk7Rrqr3ZINx7W7J4CNWsnqA19O0n/LCVJ6I6um62OduSDpPXJzixjN+z4sXLxZ8dIgIKEIEHrF/dxZ8xHzO550l9uuxxx5bnLN3dn6nfcybNy+dddZZacqUKS8EIt1dm+P8HgSdnSX2a5yzy9/yYNyTt1yxq1tuuaWIqqorFSt533335RTt6J577tnu4I0TWTwZqz8lobPFRUnA0Xki2Ogp4KDzxf4vb0jj/B7n+/Xr1xdp2lecr2N/hti/cX/2xBNPFGmGh7huVx8ixL3bk08+mVP903LBR5ysxo4dm1Nd4mB3EmtvcaDGfqyK/dzTARxPWCLCji6CUqAzRK5X+dsun5bSWRqd82l/cS+233775dSO4oFi+dsuc0TpHJGrGfv4ta99bR7TP21R4bynA5321dOFKep3lF1k3V9//fVFli/Q3uIJefnbXrBgQXEhu/rqq/NUOkG5PxW56ixl8ZvuikPHE/LqtTuKYHq40Bmi+F0ElGVxyu6Ogd5qi+BDFl9n6m1uVlzAIlBZvXp1HgN0grL4Zb0COu0rHhJFzlbUE6BzROmDeFDQl+KVUWTeb7szRPG7MqiM4yCCkYFoueAjbjLrRXHiJjWibdpXFLGqBxuxn/uyX2XhQ2fy2+4M1QrJZT0B2l8EHlH6IHIq+6pejJ72Fw1LDLQqRMsFH6961auKlaqW8Y+nKPF0jPY1efLk4glIWXSqXm4w0pGlF/s9suyr+z/ScUzIwof2FE/JovhF/P6rxTAiPRjlh9n14pwdgUfcoA60SAatI66/EXjEE+9GAWXU64guruHVOh6Rdu/WGeL8Hfuz9L3vfW/AD4xasqnd8ulJSTO7naF8elKqNsMYB3ZZljAC0BiuihMf7S9uPONmsypOYlrAam9x01EvXhG5mmURjbh4RTrKhMdw9amZJrU7Q32/lpy721s8FKyrnrPLgCN+6/XzgKaWO0P93m0wrtktGXwAAACdpy0qnAMAAO1P8AEAADSF4AMAAGgKwQcAANAUgg8AAKApBB8AAEBTCD4AAICmEHwAAABNIfgAAACaQvABAAA0heADAABoCsEHAADQFIIPAACgKQQfAABAUwg+AACAphB8AAAATSH4AAAAmkLwAQAANIXgAwAAaArBBwAA0BSCDwAAoCkEHwAAQFMIPgAAgKYQfAAAAE0h+AAAAJpC8NHGfvrTn6YRI0akf/zHf8xjUlq6dOkO43py3HHHpcmTJ+dUZ+pum8T42IZ0jieeeKLYr9Gnswz2vm2VY+WBBx4ozsNxjurLuXs4ie0S26gqzt2x/9hRo+01WFpxu8fy9PW3E//j+r/rCD7a2MUXX1z0TznllKLfH3PmzEmPPPJI+vKXv5zH9CwulOVF8qMf/Wgeu71ynre//e15TOv57Gc/m4488sg0d+7cPIZOMG/evGK/fu5zn8tj2l9cIOM4jYcE5W/v8MMPL35/nXDxjN9iuV6NutJg79tWOVZOPvnkdOedd6YzzzwzXXTRRek//uM/8hR6Mm3atGL/CUCaqxO2u+v/rif4aFPxtC4ChlmzZqUDDjggj+27N7/5zUX/6quvLvo789RTT+WhlP7n//yfDW9+ynk2bNhQ9FvRH//xHxf9gWw7Ws+kSZOK/p/8yZ8U/XYXv/FYpyuuuCI9+eST6dhjjy265cuXF7+/Trh4ljfbcVNTrl+1K3W3b+MJ79ixY3Nqe/EkNAKYeCBS1wrHSixXPPyJ9bz88svT3//936dPfOITeSo9if237777phe/+MV5DIOlp99UJ2x31/9dT/DRpr7xjW+k9evXp5NOOimP6Z/99tuvCGDiyVtfnqKWF+52vfl561vfmrZs2VJc8OkcceMW+7WVc916K54snnbaacXwlVdeWQQfd9xxR9HFOl533XXpsMMOK6Z3gksvvfSF9at2pZ72bZwLe1J9aFJqhWOlXK43vvGNRZ/eu++++4rfxGte85o8hsHU3W+qE7a76/+uJ/hoUzfffHPRf+1rX1v0B6IMYCKg6a33vve9RQASQYtsbxh8USQyRFGc973vfcVwVdw0e0oOQLsRfLSpxYsXF1mfPWUbRpZ+3KCUZadjuFHuxoEHHlj0v/WtbxX93jr//PO36/dGBCrVZYqs3cg9aVQsorrMMU/5P5El3Gj+vojliM+qV1Drz3fW1ynK5ndX8S2K0UR5/XLeGP7617+ep24T0+Iz4zvLsv47y2Xa2f9EUb1YrmrdgXL+uhhXXad6Vx5HZfZ8fHYMx7T4/KrernNvtuPOPqssZtMoIK7/b3x+1JuoVzguPyO2QfxPub1iPbvbr4MtvjuK48RvPIri9EYsY+yDuvismBbbtqocF9PLdYzjpfxt1Ocvlfuouo17u48Hor5vy3Q8AAnld8d+KtfhIx/5SDEtyneX02N9Q6NjpT/7Ptazuu7VLv6/OzE9livEcpb/Uy5f6M8xG9NjOJa5+ll1/VnX8rwY88S80cXx0GhfV88N8Xnl/8T3DMaxUZ5vqvrznfV1in6k69s4xLFSHv/l5zbaVtXlKJcz5u1Jb/5nIL+zcpvEZ5b/X/7+SzE9xjf6TZXKZasbymOjt9s9xPpU5220L8vzQ/UzynHRr39GfTuFRtsz1qu8NrITW2g7K1as2BK77thjj81jtrn77ruLadOmTXthnosuuqjoR3rrzcyWdevW5bm3KaftTPn58Zlh0qRJRfprX/takQ7lPPXlu+666174nn/4h38oPmPWrFkvjIv1qorx8fkxLfox/5lnnvnC/I3Wo5H6ModG40Jfv7PROpXbJP6vqr5PYv74vxhX3X4hxpXLEV38T3171vX0P7Hc9e+vrld122+96X3hM+rrVP5vuR0iHeOrnx3/Vyq/o9yW1XWObVcqj+nqd8axUS5/uPLKK7f7rOjie6NfiuGYJ/ZvVX05yv+NcdGv7tfyM8rp8b8xrtwGMTzUymWoH0M9ifmr26vU3e8xxsU6lfs6pkcX2yKmRVc/3stp/dnH3SnXtb7P6urzRT/GVfdLdHGcxDEcw7E+Ma3ch9GV6xTD9e8tx/V238fvNsY3Wvf431iW7sT85baL5Yx0dOXy1bdrdL09ZqMf/9fTNq3/z87WNX6j1XWL6dHvbl+X2z4+P+aJbVPdPjvb31Uxf3xeVfn5VX39zkbrVP2M6jaOz4nx1f1RbquYVlX9jOhHOr6nJzv7n/rxUF2v+rYv/79UntNjfHXfRTrGx/TQ02+qVC5n1VAeG725NsT81c+LaTFf+T3VeUM5f8xTKseV26X+GfG51eOhvHcp54tli+1WXXa6J/hoQ+UFLw72uvIHFF39wlf+WBr9X3nC25n6j7ZMx4+uVI6r/uCrN7RxMqkqbyrrJ4gYF12cDKrKk0NPF/aq+jKHRuNCX76zXKdY9+pJKZQnrOq6NjoxlcsR+6aqXI7YL/XP7k5P/xP7PKbVt1mj7y/nrV4wYl1jXHU/h+qJub5fy+O0vm6xbOWxUIr9EPPWg7Cq8rt62h7l51S3c7kcjbZL+ZuoHgflZ9TXqdwG1eUeKuU+qB+fPYn567+hUO7j7n5fjbZLebzXbxoiHePLc0hf9nF3yu0d3xnD1a76/eV89d9QeVw00t3/hEbTynG93ffleTOml8ptVD+HNFLum/jeqv4es9HV91l3+ruu9c+P/y3nry5ruV/q61Bun/ox05OYv378Ntrvff3Ocp3q565y21TPl/G/9fNnd8d5uRz1bduTnv6nr7+zmLe6veLzYl2rx2lotJ6h0bYtNZo2lMdGuYw9XRvK31F09WWIa1aMr27TRr+76mfUt0csT4yv3jtFOpaf/lHsqg2tXLmy6O+zzz5Fv5GtP5Ydyomfe+65RT+KbNVFxfMQWY59MWPGjKKllq0ntSJLuDtlBfmtF+QdKqrFcm49QRRZvfWszRhfrxQ2e/bsol+fd7D09jvLdfq7v/u7F7ZfqSyvX2Zfh9WrVxfbq6pMN2oZbOsJO11//fU7fHZPuvufaC0pptWPifj+WN/4n9L9999f9COruRTF+8r93Mi11167w3695pprin553JVi2eKzY9vVj7df/vKXeah7a9euzUO9Uy7HggULdtgu0WJUuPDCC4t+VRwD1XUqt0Esd3dZ63F8RNZ7b7vuPqfcB0Otu+Pl+OOPL/pl3bJSmf6rv/qrot+ffdydOEaj+FG1620rfIOtt/s+Wh2L8dXir+XvZiDFL/p7zG69Odrud9sbvVnXOK5jXbfebO3w+fG/cV6P+W+44YY8dpv68VX+f3zeUOnNd5brFNfK+rmrbL7+pptuKvohrm/182d8R9S7jHVvpNF5cWcG61xaFZ8XFcWrx2l4wxveUPQH0rxzs46N3lwb4rvqyxD1U8OPf/zjor8zfbl3ivWqF+midwQfHerP//zP89A25QltsE/6H/vYx17od/dDLOuTvOUtbyn6dXHiCvVWaeplXqvKC2NZ9rLe9ffi35vvDOU6xcm3/t3f+c53immNxEWiOm934qJWv1jsTKP/ieWLk+TYsV1luevdYIjWQ+rKE3UEYPXvrO+buNjHjfDf/u3fFmV0Y5nr/sf/+B9F/6ijjmr4Gd0pl6PRMsa2iu9tdPMwYcKEPLSjX//613loe3H8xvr2tmvUClPo637vr+6OsdhWZWBS/qajH+kIVstzSV/28c7cfffd8Th1u67a2lUz9WffD6b+HrPdnV970pt1XbZsWdE/9dRTi35deTw0uont7liuPsiI9y7Uj5++Pgir6s13lusUD37q393oRrkU56bq8sZDpe402n87M9BzaU/iNxx1Ksr/XbRoUZ7Sf0N9bPTm2lCaOHFiHtrRL37xizzUs97eO0WgH8v5ute9rghMu7v3oTHBBwMWT8/jaUH8ELt7YdfO3vnR6AffW/EkvP7ENLqhvkko16nRE9sYF6q5U3GCigAgKplW5x1q5Q1u7J/q95ZdjI+Te6lsvrV68Y8LXFz4yiCxN8qbo0bfGZ8Vyrbi4yIUwVw8cY1td8ghhxQ5A9ULTVyUv/a1rxXbMD4jboK7qxha1egmrWowWowrxW+hfgPdU1de1OrKi+iufOFc+QSxbAWv7MdvvdSXfdyJ4vfwve99b7tjsMwBHkgzyM08ZntjZ8fhQQcdlIf6J54s14+f7373u3nq0CjXKY7T+ndHF8aMGVP0Q5yL4sFUnJviRricr3qjPFQG43cWDRGMGzcu/df/+l9f+N/yOjUQQ31s9ObasCtES4MXXXRR0exwNIk+ZcqUIqCjdwQfDIpqUYDf/va3xXBfrFmzJg/1XdzANbqxqxdxGmzlhanRE9uyK7Nv4+a9fGdD3EBX5xlq5UUpTt7V7612cQItTZ8+vej/5V/+ZXHBihPqMcccU4yLYiC9VQY0jb6v7Ko33zEcT7rjYh7Z53FRjVyO6o1dBCDxpDG2eXkxesc73pGn9k9PTy53lYMPPrjoR07DrlIWNSyLWpX9v/mbvyn6oa/7uNPE7yJuDOPpZ/xO4vcSAXFsl+p2Gmytdsz2tShkXZx/6sdNb1t566/ywVDcQNa/u+yqRYnjTfRxbrryyivTunXrXpgnzkNDbaC/s1iPuEZHsLxixYoX/ifOo0NtoMdG6M21YVeIYzSO3euuu+6Fh2ICkN4RfLSh8sakpycOjW7myycFjU6W5cWsvzfs8XSiLNv5v//3/85jtylfovXDH/6w6NeV2covf/nLi347KHNrulunqjIb/5xzzulXVvxAlBeleELbG+edd16RqxBPvuPmPk6ocfGLoKkvy14+ne3rE6o4lqIcenk8NSqrG8dpXIxiOcsnf90pj/dGyxFBYVzQ4nNaSdzMxjaPZYsiHr3V6Ka0Pw8DQmzj2C4RAMV2in7cvFSLSvR3H3eC2Cbx+4jjK7ZL/E7iBi8CknhSW91OfdVqx2xZN+Df/u3fin5dWcx0V74tvq/KJ/LdrVNV5ALHNo/9Eg+UqvUUmmGgv7Oy7lS8yHOwHwY089jozbVhoPp67xTiWlnew/y///f/ij49E3y0oZe85CVFv6dKqXFRrD61CRdccEHRf9vb3lb0q+LEWj5d6a+FCxcWn9HoZrD80Ub2ev1pRdxcxfdHcY6BXLCbrayU+MlPfrLhE5jY/uX48ilbPWDsy43lQJQn60bfFzcz1bbVo1xr7MfYn+UTyais2Negqax0Xx53VbFd6sfnUCmP97g5rItyuyEaDWglcXNTbrf4zTTab7HP4kl7KW5G43dUvUGJ4dNPPz2n+q4sYhVP88MZZ5xR9Eutso9DHMfdGYynr3VRrDN+U3HOivUsnybH8EBv8FrtmI1ANM4JEYDW62LEMRbXm5her+zbyqrBdaOb+ljPcnyZe1w/z8c8vX2oMxAD/Z2VufTVBxHxfzur89HTb6rUacdGX++d6B/BRxuKH3vo6aQXN5tRzCfKRkY2YPTLJ5flTXOpPMEOtBxx3DDFk/1G4mIcF824WEfZyLI4TyxXlJ+Ni8Bll12W524PcdNRVjqLdYobtLLoRZQNju1f3vS8+c1vLk7A8WS0nK9c9xg/1M4+++zie+L74sVU8f3RxQUhtn3ZmkqIYgURgET54PLlSeULlOJ/6hfg7sRnx/EWx11sj3Kfx/qX26sUn11+frlccRGI/y+P98jWjvHlPLEese3Lm7HuxJPK+JwIimM5yv+P4Vi2Rq2btIJYpjJojP0W619upxiOstux/KXyZjSKI5TFf6J89EAu+mWrVuUDhTiOq/qyj4dKmasa+zG+u7q+5VPZWI5yuRrdaPZHHJfxnXGcVn8n5X4aSODVisdstMIUos5adXvGMRbnlq9+9avF9HZS5tKXv5NyO8e5JdazrEwd16/YH3FeLM9Tse7lSyKH2kB/Z3/9139d9ONBRPm/ZUXpRnr6TTUylMdGec6LzyyXpX5tGEzxud3dO5W/uQiyYj+U6xrbtCyaXDaMwk5soS0dm9vJ3nrzlcd0Kduqjn60i731B1Okt54Ainbnq21ql6JN65in3rZ1I+XndzdvfH75nVtvCvPYbaIN7nJ6dFtvfIv5Gi1XTI/1rCvbDt96YsxjelYuc6M2vavjQn++M7ZzuT+iK7d1fEdVfEb8fzlfbIeYJ/63/p0xvdFy9GRn/xPbOJYrtnl1GWJfVrd/uS4xb2yf6GIflf9X/Y5y3p7E/zfa59Vjt9E89eM1tl192ev7L9Ixrb7t43NiWqN1r+vuM0K5/6ptxg+1WI743jiuymWP7V7fhqG6jtEv1y/S9WO3/JydKfdLT/PG9+5sH3enp+1d1d185XFdfnd9OeP/ym0Xy1UuU6PP62lZ6vs+vjc+N7pY1/jf6GJZyu+LdE/ie7qbb7CO2e709D/dHecxbzktuljPWN9Gv4eezg3lduut+Jz6fm30+f35zvK8HNPif6OLdP19EeVxVs5X/r7K7VjV03J0pzf/E9/Vm99ZTKtvr+r9QHSxjvF/MRyfW9XTb6q75RyqY6PROsfnxjKWevodxT6KadXfTaP5q+NiuPzOcj2q3xfbLdahPBaii3RsY3pnRPzZuuFoM1EMI56Gbv1BDfgJWDxJiMh+6w+qrYo9MfiiKE88Ud96si3K1tbF0544Tpw2GO7iaWfkZEZl0/qT4SiusvUmqShuuquaCwZ6L3IzIudma/Ax5I0doNhV22r0EqT+iCI0ZZaiwIPyRU77NigKFsdK1AFpNA2GmwjCQ1kHr6ps5rvaVCsAXQQfbSrqV8TT6SgT3JtKYd0p2+7/8Ic/XPQZ3qp1U+JpblnOtixbHPUPGuWIwHBTLUdflv2OLn438QQ1fkf1N1IDkJJiV22szNofSDZhVKaK5jlb8V0H7BpxXF188cVF04Hl0924kYoKde9///uHpJIftKMoqvGZz3ym+K1EYB7inBy/lWjkQW4ytAfFrppL8AEAADSFYlcAAEBTCD4AAICmEHwAAABNIfgAAACaQvABAAA0heADAABoCsEHAADQFIIPAACgKQQfAABAUwg+AACAJkjp/wNHJ3XxevseQQAAAABJRU5ErkJggg==)"
      ],
      "metadata": {
        "id": "StVtZSY89V7b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us now discuss the least squares method for linear as well as non-linear relationships."
      ],
      "metadata": {
        "id": "7bkQq-EK-NeA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **3.2.1.1 Least Squares method for fitting a linear relationship (Linear Regression)**"
      ],
      "metadata": {
        "id": "kBcr_LBC-WrF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we establish the relationship between variables in the form of the equation $y = a + bx$. Hence this method is also called **fitting a straight line**.\n",
        "\n",
        "Consider a set of $n$ values $(x_1,y_1),(x_2,y_2),..,(x_n,y_n)$.\n",
        " Suppose we have to find linear relationship in the form $y = a + bx$ among the above set of $x$ and $y$ values:\n",
        "\n",
        "The difference between observed and estimated values of $y$ is called **residual** and is given by\n",
        "\n",
        "$$R_i=y_i(a+b~x_i) $$\n",
        "\n",
        "In the *least square method*, we find $a$ and $b$ in such a way that $\\sum R_i^2$ is *minimum*. Let\n",
        "\n",
        "$$T=\\sum_{i=1}^n R_i^2=\\sum_{i=1}^n(y_i-(a+bx_i))^2$$\n",
        "\n",
        "The condition for $T$ to be minimum is that, $\\frac{\\partial T}{\\partial a}=0$ and $\\frac{\\partial T}{\\partial b}=0$ i.e.,\n",
        "\n",
        "$$2\\sum_{i=1}^n(y_i-(a+bx_i))(-1)=0$$\n",
        "and\n",
        "$$2\\sum_{i=1}^n(y_i-(a+bx_i))(-x_i)=0$$\n",
        "i.e.,\n",
        "\n",
        "$$\\sum_{i=1}^ny_i-\\sum_{i=1}^na-\\sum_{i=1}^nbx_i=0,$$\n",
        "and\n",
        "$$-\\sum_{i=1}^nx_iy_i+\\sum_{i=1}^nax_i+\\sum_{i=1}^nbx_i^2=0$$\n",
        "i.e.,\n",
        "\n",
        "$$\\sum_{i=1}^ny_i=na+b\\sum_{i=1}^nx_i$$\n",
        "and\n",
        "$$\\sum_{i=1}^nx_iy_i=a\\sum_{i=1}^nx_i+b\\sum_{i=1}^nx_i^2$$\n",
        "\n",
        "These are called **normal equations.** By solving these, we get **a** and **b**. Line of best fit can now be formed with these values obtained."
      ],
      "metadata": {
        "id": "6IpbzUOC-bPv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example 1:** Fit a straight line to the following set of data points:\n",
        "$$(X,Y): (1,3), (2,4), (3,5), (4,6), (5,8)$$"
      ],
      "metadata": {
        "id": "PNyt0IPvFzL7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Solution:** We shall prepare the table and get\n",
        "$$\\sum x_i=15, \\sum y_i=26, \\sum x_i^2=55, \\sum x_iy_i=90$$\n",
        "\n",
        "Normal equations for fitting $y=a+bx$ are:\n",
        "\n",
        "$$\\sum y=na + b\\sum x$$\n",
        "$$\\sum xy=a\\sum x+ b\\sum x^2$$\n",
        "\n",
        "i.e.,\n",
        "$$26=5a+15b$$\n",
        "$$90=15a+55b$$\n",
        "\n",
        "Solving, you will get $a=1.6$ and $b=1.2$\n",
        "\n",
        "Hence, straight line is $y=1.6+1.2x$."
      ],
      "metadata": {
        "id": "4HHMV_QdGAiT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **3.2.1.2 Least Squares method for fitting a non-linear relationship (Non-linear Regression)**"
      ],
      "metadata": {
        "id": "Norkuwr2QWsR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fitting polynomial function using Least Square Method**\n",
        "\n",
        "Let $y=a_1+a_2x+a_3x^2+..+a_mx^{m1}$ be the curve of best fit for the data set $(x_1,y_1),(x_2,y_2),..,(x_n,y_n)$.\n",
        "\n",
        "Using the Least Square Method, we can prove that the normal equations are:\n",
        "\n",
        "$$\\sum y_i = na_1+a_2\\sum x_i+a_3\\sum x_i^2+...+a_m\\sum x_i^{m-1}$$\n",
        "\n",
        "$$\\sum x_iy_i=a_1\\sum x_i+a_2\\sum x_i^2+...+a_m\\sum x_i^m$$\n",
        "$$......................$$\n",
        "$$......................$$\n",
        "\n",
        "$$\\sum x_i^{m-1}y_i=a_1\\sum x_i^{m-1}+a_2\\sum x_i^m+....+a_m\\sum x_i^{2m-2}$$\n",
        "\n",
        "Solving these, we get $a_1,a_2,,..,a_m$. Curve of best fit can now be formed with these values obtained."
      ],
      "metadata": {
        "id": "R1XddWpVQcaH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example 2:** Fit a second order polynomial to the given data:\n",
        "$$(X,Y): (1,6), (2,11), (3,18), (4,27)$$"
      ],
      "metadata": {
        "id": "V5b662dxSOfA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Solution:** Let $y=a_1+a_2x+a_3x^2$ be the required polynomial.\n",
        "\n",
        "Normal equations are:\n",
        "$$\\sum y=na_1+a_2\\sum x+ a_3\\sum x^2$$\n",
        "\n",
        "$$\\sum xy=a_1\\sum x+a_2\\sum x^2+a_3\\sum x^3$$\n",
        "\n",
        "$$\\sum x^2y=a_1\\sum x^2+a_2\\sum x^3+a_3\\sum x^4$$\n",
        "\n",
        "Using the given data, we can find:\n",
        "\n",
        "$$\\sum x=10, \\sum y=62, \\sum x^2=30, \\sum x^3=100,\\sum x^4=354,\\sum xy=190, \\sum x^2y=644$$\n",
        "\n",
        "Solving the equations accordingly, we get:\n",
        "$$a_1=3, a_2=2, a_3=1$$\n",
        "\n",
        "Therefore, the curve of best fit is represented by the polynomial $y=3+2x+x^2$."
      ],
      "metadata": {
        "id": "V7zmULTNS3yL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Remark:** We may use the same approach to solve equations such as\n",
        "\n",
        "$$y=a_0+a_1x_1+a_2x_2+a_3x_3+...+a_{n-1}x_{n-1}+a_nx_n$$\n",
        "\n",
        "Where $x_1,x_2,...,x_n$ are the arguments or independent variables, and $a_0,a_1,a_2,...,a_n$ are the constants to be determined. It is called **multivariate** or **multiple linear equation**. Detail discussions will be done in the following segments."
      ],
      "metadata": {
        "id": "CccTjzRtcUfQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3.3 Mean Square Error (MSE)**\n"
      ],
      "metadata": {
        "id": "TeluHVpwUXxw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **mean squared error (MSE)** is a commonly used metric to assess an algorithm's performance.\n",
        "\n",
        "The formula to calculate the MSE is as follows:\n",
        "\n",
        "$$MSE = \\frac{1}{n}\\sum_{i=1}^n(y_i-\\bar{y_i})^2$$\n",
        "\n",
        "Where\n",
        "\n",
        "*   $n$ - the total number of terms for which the error is to be calculated\n",
        "*   $y_i$ - the observed value of the variable\n",
        "*   $\\bar{y_i}$ - the predicted value of the variable\n",
        "\n",
        "The mean square error is the average of the square of the difference between the observed and predicted values of a variable.\n",
        "\n",
        "In Python, the *MSE* can be calculated rather easily, especially with the use of lists.\n",
        "\n"
      ],
      "metadata": {
        "id": "bJGV9jeRVrrV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "How to calculate *MSE*?\n",
        "\n",
        "\n",
        "\n",
        "1.   Calculate the difference between each pair of the observed and predicted value\n",
        "2.   Take the square of the difference value\n",
        "3.   Add each of the squared differences to find the cumulative values\n",
        "4.   In order to obtain the average value, divide the cumulative value by the total number of items in the list\n",
        "\n"
      ],
      "metadata": {
        "id": "lafSwsMnXINI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example:** Assume you've been given the observed and predicted values and want to calculate the *MSE*. The steps outlined above will be carried out in the following order:"
      ],
      "metadata": {
        "id": "i4_-MXM3Xk50"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = [11,21,19,17.5,10]\n",
        "y_bar = [12,18,19.5,18,14]\n",
        "\n",
        "#variable to store the summation of differences\n",
        "summation = 0  \n",
        "\n",
        "#finding total number of items in list\n",
        "n = len(y) \n",
        "\n",
        "#looping through each element of the list\n",
        "for i in range (0,n):  \n",
        "  #finding the difference between observed and predicted value\n",
        "  difference = y[i] - y_bar[i]  \n",
        "  #taking square of the differene \n",
        "  squared_difference = difference**2  \n",
        "  #taking a sum of all the differences\n",
        "  summation = summation + squared_difference \n",
        "  #dividing summation by total values to obtain average \n",
        "MSE = summation/n  \n",
        "print(\"The Mean Square Error is: \" , MSE)"
      ],
      "metadata": {
        "id": "BXijvklAHulQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**If we are to use `scikit` library, mean squared error can be calculated using `mean_squared_error()` function.**\n"
      ],
      "metadata": {
        "id": "iTOQO_3wZUVZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "  \n",
        "# Given values\n",
        "Y_true = [11,21,19,17.5,10]  # Y_true = Y (original values)\n",
        "  \n",
        "# calculated values\n",
        "Y_pred = [12,18,19.5,18,14]  # Y_pred = Y'\n",
        "  \n",
        "# Calculation of Mean Squared Error (MSE)\n",
        "mean_squared_error(Y_true,Y_pred)"
      ],
      "metadata": {
        "id": "L_RKp6A1YEOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.3.1 Root Mean Squared Error (RMSE)**"
      ],
      "metadata": {
        "id": "K5JNwI0mmWvU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Root mean squared error *(RMSE)* is the square root of the mean of the square of all of the error. The use of *RMSE* is very common, and it is considered an excellent general-purpose error metric for numerical predictions.\n",
        "$$RMSE=\\sqrt{\\frac{1}{n}\\sum_{i=1}^n(y_i-\\bar{y_i})^2}$$\n",
        "\n",
        "where $\\bar{y_i}$ are the observations, $y_i$ predicted values of a variable, and $n$ the number of observations available for analysis. *RMSE* is a good measure of accuracy, but only to compare prediction errors of different models or model configurations for a particular variable and not between variables, as it is scale-dependent."
      ],
      "metadata": {
        "id": "Qo8SiKY4mpGZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **To Do**"
      ],
      "metadata": {
        "id": "of84ExxVaP4_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Fit a straight line to the set of data points: $(X,Y): (1,1), (2,1), (3,2), (4,2), (5,4)$. Also find the mean squared error *(MSE)* using `numpy` module. "
      ],
      "metadata": {
        "id": "sQQf2_rqaTBR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3.4 Correlation Coefficient**"
      ],
      "metadata": {
        "id": "kmH8AkzceKHc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is represented by the following equation:\n",
        "\n",
        "$$r=\\displaystyle\\frac{N\\sum xy-(\\sum x)(\\sum y)}{\\sqrt{[N\\sum x^2-(\\sum x)^2][N\\sum y^2-(\\sum y)^2]}}$$\n",
        "\n",
        "Here, $N$ shows the number of pairs of scores, $\\sum xy$ shows the sum of products of paired scores, $\\sum x$ shows sum of $x$ scores, $\\sum y$ shows sum of $y$ scores, $\\sum x^2$ shows sum of squared $x$ scores, and $\\sum y^2$ shows sum of squared $y$ scores.\n"
      ],
      "metadata": {
        "id": "WyzA5ylTejJu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example 1:** $(x,y):$ $(1,2), (3,5), (4,5), (4,8)$. Use the formula above to find the correlation coefficient, as well as Python to find it."
      ],
      "metadata": {
        "id": "pbY-dM77iyUM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Solution:** From the data points, we get\n",
        "$$\\sum xy=69, \\sum x=12, \\sum y=20, \\sum x^2=42, \\sum y^2=118$$\n",
        "\n",
        "$$\\therefore r=\\frac{(4)(69)-(12)(20)}{\\sqrt{[(4)(42)-(12)^2][(4)(118)-(20)^2]}}=0.866$$"
      ],
      "metadata": {
        "id": "7NMqz1_Qs_Wb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using Python:**\n",
        "\n",
        "In order to work on Correlation Coefficient, we can use the data points. We can write the following\n"
      ],
      "metadata": {
        "id": "EcCPGrKJvf-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "x=([1,3,4,4])\n",
        "y=([2,5,5,8])\n",
        "z=np.corrcoef(x,y)\n",
        "z\n"
      ],
      "metadata": {
        "id": "lOV6U2lGw-jW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This gives the result of 0.8660254. This value of sample correlation coefficient is clearly showing a strong positive correlation.\n"
      ],
      "metadata": {
        "id": "bYM1lkg6xaCC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.4.1 Rank correlation Coefficient**"
      ],
      "metadata": {
        "id": "2TSB3MKzxqKb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The *Spearman correlation coefficient* is defined as the *Pearson correlation coefficient* between the rank variables.\n",
        "\n",
        "For a sample of size $n$, the $n$ raw scores $X_{i},Y_{i}$ are converted to ranks $R(X_i), R(Y_i)$, and $r_s$ is computed as\n",
        "\n",
        "$$r_s=\\rho_{R(X),R(Y)}=\\frac{Cov(R(X),R(Y))}{\\sigma_{R(X)}\\sigma_{R(Y)}}$$\n",
        "\n",
        "Where\n",
        "\n",
        "\n",
        "*   $\\rho$ denotes the usual Pearson correlation coefficient, but applied to the rank variables,\n",
        "*   $Cov(R(X),R(Y))$ is the *covariance* of the rank variables,\n",
        "*   $\\sigma_{R(X)}$ and $\\sigma_{R(Y)}$ are the *standard deviations* of the rank variables.\n",
        "\n",
        "Only if all $n$ ranks are distinct integers, it can be computed using the popular formula\n",
        "\n",
        "$$r_s=1-\\frac{6\\sum d_i^2}{n(n^2-1)}$$\n",
        "\n",
        "Where\n",
        "\n",
        "$d_i=R(X_i)-R(Y_i)$ is the difference between the two ranks of each observation, $n$ is the number of observations."
      ],
      "metadata": {
        "id": "cAJfleZ9zIRM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example 2:** The raw data in the table below is used to calculate the correlation between a person's *IQ*$(X_i)$ and the number of hours spent in front of the television per week$(Y_i)$ in this example.\n",
        "\n",
        "$$(X_i,Y_i): (106,7),(100,27),(86,2),(101,50),(99,28),(103,29),(97,20),(113,12), (112,6),(110,17)$$"
      ],
      "metadata": {
        "id": "qjwxEmq-2VxL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Computing the Spearman Rank Correlation Coefficient Using Pandas:**"
      ],
      "metadata": {
        "id": "yMxr2Mt76NbS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The various correlation coefficients, including Spearman, can be computed via the `corr()` method of the `Pandas` library.\n",
        "\n",
        "For $n$ random variables, it returns an $n\\times n$ square matrix $R$. $R(i,j)$ indicates the Spearman rank correlation coefficient between the random variable $i$ and $j$. As the correlation coefficient between a variable and itself is $1$, all diagonal entries $(i,i)$ are equal to unity. In short:\n",
        "\n",
        "$$R(i,j)=\\begin{cases}\n",
        "r_{i,j}, & if ~~i\\neq j\\\\\n",
        "1, & Otherwise\n",
        "\\end{cases}$$\n",
        "\n",
        "Note that the correlation matrix is symmetric as correlation is symmetric, i.e., $M(i,j)=M(j,i)$. Let's take our simple example from the previous section and see how to use Pandas' `corr()` fuction:"
      ],
      "metadata": {
        "id": "Q_s_Ul4t6Tt4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns # For pairplots and heatmaps\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "kuBY_Nr1xJQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating dataframe using Pandas\n",
        "\n",
        "x_simple = pd.DataFrame([(106,7),(100,27),(86,2),(101,50),(99,28),(103,29),(97,20),(113,12), (112,6),(110,17)],\n",
        "                        columns=[\"X\",\"Y\"])\n",
        "my_r = x_simple.corr(method=\"spearman\") # To find rank correlation\n",
        "print(my_r)"
      ],
      "metadata": {
        "id": "k0izqW1C9W3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Visualizing the Correlation Coefficient:**"
      ],
      "metadata": {
        "id": "PKZmw--P-eUm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's visualize the Spearman correlation using `seaborn` library."
      ],
      "metadata": {
        "id": "Ju-hJ_n_-sgO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ax = sns.heatmap(my_r,vmin=-1, vmax=1, annot=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "3VL908g99bfz",
        "outputId": "fe246fc4-0e99-424e-a0fb-6cff6faa10d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.4.2 R-squared and Adjusted R-squared**"
      ],
      "metadata": {
        "id": "ivSN0pR9FR9e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**R-squared** estimates the differences in one variable (dependent variable) in relation to differences in a second variable (independent variable). It can be calculated using the formula given below:\n",
        "\n",
        "$$R^2=1-\\frac{RSS}{TSS}$$\n",
        "\n",
        "Where\n",
        "* $R^2$ - coefficient of determination\n",
        "* $RSS=\\displaystyle\\sum_{i=1}^n(y_i-f(x_i))^2$, Residual sum squared.\n",
        "* $TSS=\\displaystyle\\sum_{i=1}^n(y_i-\\bar{y})^2$, total sum of squares\n"
      ],
      "metadata": {
        "id": "VFcsXOxVFkZM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Adjusted R-Squared:**\n",
        "\n",
        "Adjusted R-squared adjusts the measurements/statistic on the basis of a number of independent variables. It is represented by the following equation:\n",
        "$$Adjusted~R^2=1-\\frac{(1-R^2)(N-1)}{N-p-1}$$\n",
        "\n",
        "Here, $R^2$ shows coefficient of determination (R-squared) or square of correlation coefficient (R); $N$ shows number of observations/data points, and $p$ shows number of parameters/independent variables/independent regressors.\n",
        "\n",
        "Note that Adjusted $R^2 \\leq R^2$.\n",
        "\n",
        "Note that decrease in the number of useless\n",
        "variables results in an increase in the value of Adjusted $R^2$, whereas increase in the number of useless variables results in decrease in the value of Adjusted $R^2$.\n"
      ],
      "metadata": {
        "id": "onHqhmJx41Qo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can calculate the $R^2$ value using the following code."
      ],
      "metadata": {
        "id": "LBxblLFAQVkb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_values = [1,2,3,4,5,6]   # Data points \n",
        "y_values = [1,5,25,30,22,45]\n",
        "\n",
        "correlation_matrix = np.corrcoef(x_values, y_values)\n",
        "correlation_xy = correlation_matrix[0,1]\n",
        "r_squared = correlation_xy**2\n",
        "\n",
        "print(r_squared)"
      ],
      "metadata": {
        "id": "Boqm39Nw_ZC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3.5 Regression Analysis**"
      ],
      "metadata": {
        "id": "2EZVf612QzFe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imagine you want to know if the income of a person has anything to do with the area of his/her house. To test this hypothesis, you ask many of your friends about both their income and their location. Then, you try to plot the data and see if there is a clear linear relationship."
      ],
      "metadata": {
        "id": "tnSS6Vp8RAsQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This equation is a simple one, which is as follows:\n",
        "\n",
        "$$y=b + mx$$\n",
        "In this equation, we find the output $y$ by multiplying the input $x$ by the slope $m$ and add this to the $y$-intercept $b$. The output is also called the **response variable,** as we are trying to evaluate or predict it."
      ],
      "metadata": {
        "id": "4-nRMJVGTZCh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.5.1 Simple Linear Regression**\n",
        "\n"
      ],
      "metadata": {
        "id": "Hzi_NjsIVBgB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For **simple linear regression** analysis, we want to predict the output by training a machine learning model on both the input and the output. This allows us to get the slope and use both the new input and the learned slope to predict what will happen in the next output.\n",
        "\n",
        "$$y=b+mx$$\n",
        "\n",
        "So, our goal is to find $m$ and $b$, such that error is minimized. While predicting using the model, the least error will be considered the most accurate, and it can be done with the help of mean squared error $(MSE)$ and R-Squared. \n",
        "\n",
        "Here we will use least squared method to determine the unknowns $b$ and $m$. Although, it can be also done with the help of **gradient decent method**(Which is an iterative method). So, there are two popular methods to build a model."
      ],
      "metadata": {
        "id": "L8HgSsuJWShD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **3.5.1.1 Simple Linear Regression Hands-on Projects in Python** "
      ],
      "metadata": {
        "id": "5O1mNMMuaLCh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us start with the simple linear regression project.\n",
        "\n",
        "We start with the libraries."
      ],
      "metadata": {
        "id": "zPuXM9_sdEFx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "lhwVjQOCdVJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We load the data. You can download the data from [https://drive.google.com/file/d/1PqpDdEUtic0Egn6Sk55YWBpA4GrI2YuO/view?usp=sharing]"
      ],
      "metadata": {
        "id": "NjYXWSiwdXeS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv ('income.data.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "P10cJtmsdbXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We then choose the input and output variables and split the data.\n"
      ],
      "metadata": {
        "id": "Ics_eN-TfYTk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y=df.happiness\n",
        "X=df.income\n",
        "X_train,X_test,y_train,y_test=train_test_split(\n",
        "pd.DataFrame(X),y,test_size=0.3,random_state=42)"
      ],
      "metadata": {
        "id": "onFqxm5me5qK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, we fit the model using the Sklearn linear regression\n",
        "module."
      ],
      "metadata": {
        "id": "FhbuPRrGf0kv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "regressor = LinearRegression()\n",
        "regressor.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QH34S3Cpf1aG",
        "outputId": "70b786a7-5db6-4a06-ce10-04c7e38b67d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression()"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After that, we test the model on the test data."
      ],
      "metadata": {
        "id": "i3yWBI33f7_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_prediction = regressor.predict(X_test)\n",
        "RMSE = np.sqrt(mean_squared_error(y_true = y_test, y_pred = y_prediction))\n",
        "print(RMSE)"
      ],
      "metadata": {
        "id": "4SoOlrtnf9E_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, let us plot the fitted slope to link everything together."
      ],
      "metadata": {
        "id": "UoOZzZfFgVv1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# add your actual vs. predicted points\n",
        "plt.scatter(y_test, regressor.predict(X_test))\n",
        "# add the line of perfect fit\n",
        "straight_line = np.arange(0, 8)\n",
        "plt.plot(straight_line, straight_line)\n",
        "plt.title(\"Fitted Values\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "qFGGSrDGgOKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.5.2 Multiple Linear Regression**"
      ],
      "metadata": {
        "id": "RfcKnZoeL8hM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A case of multiple or multivariate linear regression is when there are two or more independent variables.\n",
        "\n",
        "When there are only two independent variables, the estimated regression function is $f(x_1, x_2) = b_0 + b_1x_1 + b_2x_2$. It is a three-dimensional representation of a regression plane. The goal of regression is to find the values of the weights $b_0, b_1$, and $b_2$ that bring this plane as close to the actual responses as possible while yielding the minimum *RSS*.\n",
        "\n",
        "The situation when there are more than two independent variables is similar, but more general. When the number of inputs is $r$, the estimated regression function is $f(x_1,..., x_r) = b_0 + b_1x_1 +... +b_rx_r$, and there are $r + 1$ weights to be determined."
      ],
      "metadata": {
        "id": "dqCVvGOML_Wc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **3.5.2.1 Multiple Linear Regression Hands-on Projects in Python**"
      ],
      "metadata": {
        "id": "VVxZNi56M9cB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we apply multiple linear regression on the 50_startups dataset, you can click [https://drive.google.com/file/d/10lDWWlSDUij8HaJNBhzAzfb6vBSMJEdM/view?usp=sharing] to download the dataset.\n",
        "\n",
        "Now, let us see how to use `sklearn` to perform regression\n",
        "analysis and also understand interaction models.\n",
        "\n",
        "We start, as always, by importing the libraries."
      ],
      "metadata": {
        "id": "6NkfOrhpNGvm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "metadata": {
        "id": "iaDC5QSngj5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we load the dataset."
      ],
      "metadata": {
        "id": "c5IDvuBoO6lv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('50_Startups.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "3Yi5h7dsO3OF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here you can see that there are $5$ columns in the dataset where the **state** stores the categorical data points, and the rest are numerical features.\n",
        "\n",
        "Now, we have to classify independent and dependent features:"
      ],
      "metadata": {
        "id": "rJ820RMGTryj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are total 5 features in the dataset, in which basically profit is our dependent feature, and the rest of them are our independent features:"
      ],
      "metadata": {
        "id": "asRqZ_r95VH0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#separate the other attributes from the predicting attribute\n",
        "x = df.drop('Profit',axis=1)\n",
        "#separte the predicting attribute into Y for model training \n",
        "y = df.iloc[:, 4]"
      ],
      "metadata": {
        "id": "Yw5dpyxr5bEz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Handling categorical variables:**\n"
      ],
      "metadata": {
        "id": "EoTqWx7u55-E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In our dataset, there is one categorical column State, we have to handle this categorical values present inside this column for that we will use pandas `get_dummies()` function:"
      ],
      "metadata": {
        "id": "cnEOq_sT58un"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# handle categorical variable\n",
        "states=pd.get_dummies(x,drop_first=True)\n",
        "# dropping extra column\n",
        "x= x.drop('State',axis=1)\n",
        "# concatenation of independent variables and new categorical variable.\n",
        "x=pd.concat([x,states],axis=1)"
      ],
      "metadata": {
        "id": "pwdOCoqj6ORz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Splitting data**"
      ],
      "metadata": {
        "id": "s5G5DCfj62vV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we have to split the data into training and testing parts for that we use the scikit-learn `train_test_split()` function."
      ],
      "metadata": {
        "id": "KG2tKH4C67_P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the dataset into the Training set and Test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.2)"
      ],
      "metadata": {
        "id": "4FPGGDUYA1uT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Applying model**"
      ],
      "metadata": {
        "id": "BXY1b9z99Sp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we apply the linear regression model to our training data, first of all, we have to import linear regression from the scikit-learn library, there is no other library to implement multiple linear regression we do it with linear regression only."
      ],
      "metadata": {
        "id": "7-ZgOJ2d9kEz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing module\n",
        "from sklearn.linear_model import LinearRegression\n",
        "# creating an object of LinearRegression class\n",
        "LR = LinearRegression()\n",
        "# fitting the training data\n",
        "LR.fit(X_train,y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04640Rbn82Hs",
        "outputId": "4b33a9eb-58dc-4198-e752-d3783659aa2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression()"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "finally, if we execute this then our model will be ready, now we have `x_test` data we use this data for the prediction of **profit**. "
      ],
      "metadata": {
        "id": "lxRAO2yR9zNe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_prediction =  LR.predict(X_test)\n",
        "y_prediction"
      ],
      "metadata": {
        "id": "MafUto7y96tg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we have to compare the **y_prediction** values with the original values because we have to calculate the accuracy of our model, which was implemented by a concept called **r2_score**. lets discuss briefly on **r2_score**:"
      ],
      "metadata": {
        "id": "knlmWfOj-EoW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing r2_score module\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "# predicting the accuracy score\n",
        "score=r2_score(y_test,y_prediction)\n",
        "print('r2 score is' ,score)\n",
        "print('mean_sqrd_error is',mean_squared_error(y_test,y_prediction))\n",
        "print('root_mean_squared error of is',np.sqrt(mean_squared_error(y_test,y_prediction)))"
      ],
      "metadata": {
        "id": "F1UM7N1F99qw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can see that the accuracy score is greater than $0.93$ it means we can use this model to solve multiple linear regression, and also mean squared error rate is also low."
      ],
      "metadata": {
        "id": "BDhpokJmIiJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.5.3 Polynomial Regression**"
      ],
      "metadata": {
        "id": "HZR5bDzh4mFu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What is Polynomial Regression?**\n",
        "\n",
        "Polynomial regression is a special case of linear regression in which a polynomial equation with a curvilinear relationship between the target variable and the independent variables is fitted to the data.\n",
        "\n",
        "In a curvilinear relationship, the value of the target variable changes in a non-uniform manner with respect to the predictor (s).\n",
        "\n",
        "In Linear Regression, with a single predictor, we have the following equation:\n",
        "$$Y=\\theta_0+\\theta_1x$$\n",
        "Where \n",
        "\n",
        "$Y$ is the target\n",
        "\n",
        "$x$ is the predictor\n",
        "\n",
        "$\\theta_0$ is bias\n",
        "\n",
        "and $\\theta_1$ is the weight in the regression equation\n"
      ],
      "metadata": {
        "id": "OqxEETEb4r00"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This linear equation can be used to represent a linear relationship. But, in polynomial regression, we have a polynomial equation of degree $n$ represented as:\n",
        "$$Y=\\theta_0+\\theta_1x+\\theta_2x^2+\\theta_3x^3+....+\\theta_nx^n$$\n",
        "Where;\n",
        "\n",
        "$\\theta_0$ is the bias,\n",
        "\n",
        "$\\theta_1,\\theta_2,...,\\theta_n$ are the weights in the equation of the polynomial regression,\n",
        "\n",
        "and $n$ is the degree of the polynomial"
      ],
      "metadata": {
        "id": "SrlJulJf_K4E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **3.5.3.1 Polynomial Regression Hands-on Projects in Python**"
      ],
      "metadata": {
        "id": "ZM7p6U5GAxXQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset for this tutorial can be downloaded from [https://drive.google.com/file/d/1SOCxI3veCh1fCBW2EBB-wn7xhGs3AWEk/view?usp=sharing]. In this implementation session, we must predict a team member's salary based on their position level in the company.\n",
        "\n",
        "To get started, we import the required libraries for this session and load the dataset."
      ],
      "metadata": {
        "id": "-bibcA_3A613"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Importing the libraries**"
      ],
      "metadata": {
        "id": "5R7HHTmyCjbs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "ihGoXtaD-qra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Importing the dataset**"
      ],
      "metadata": {
        "id": "6uyg10BjCwXc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this step, we import the dataset and create a dataframe."
      ],
      "metadata": {
        "id": "nmxRdYmTCydY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv('Position_Salaries.csv') # read the dataset\n",
        "dataset"
      ],
      "metadata": {
        "id": "Qmo2FQ1TC5qP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This dataset contains information on how employees of a particular company are paid."
      ],
      "metadata": {
        "id": "mgBJxIChDEZs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Splitting the data into features and labels**"
      ],
      "metadata": {
        "id": "WFruFDXBEZmG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = dataset['Level']\n",
        "y = dataset['Salary']\n"
      ],
      "metadata": {
        "id": "hc33CY4wDSqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Fitting the curve of degree four**"
      ],
      "metadata": {
        "id": "u6_sELleEfIj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this step, we will try to fit polynomial of degree 4 to the dataset. The code below explains how this is done."
      ],
      "metadata": {
        "id": "gTM5aeCxEkbx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "order=4  # Degree of the polynomial\n",
        "f=np.polyfit(X,y,order) # Fit the polynomial of degree three\n",
        "p=np.poly1d(f)     #defining a polynomial function\n",
        "print(p)"
      ],
      "metadata": {
        "id": "nTyLnMeMDWQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **The polynomial regression results visualization**"
      ],
      "metadata": {
        "id": "ACvX5vtlIDpb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To visualize the polynomial regression results, lets execute the code below."
      ],
      "metadata": {
        "id": "q3w7xyBSIFLk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_x = np.linspace(min(X),max(X),2*len(X))\n",
        "model_y = p(model_x)\n",
        "plt.plot(model_x,model_y,'-o',X,y,'*')\n",
        "plt.xlabel('Level')\n",
        "plt.ylabel('Salary')\n",
        "plt.title('Level vs. Salary')"
      ],
      "metadata": {
        "id": "6lgJq7vkHHXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **A new result prediction with polynomial regression**"
      ],
      "metadata": {
        "id": "OuAyzUwJId-F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we predict a new output with the polynomial regression model. Lets execute the code below and see the output."
      ],
      "metadata": {
        "id": "R8emWn6fIf1W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xnew=[[6.5]]\n",
        "ypred=p(xnew)\n",
        "print('The predicted value is: ', ypred)"
      ],
      "metadata": {
        "id": "9DA7cqABHe1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Quantitative Measure(MSE)**"
      ],
      "metadata": {
        "id": "O3XarzX4MjGk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "y = dataset[['Level']]\n",
        "ypred1 = p(dataset[['Salary']])\n",
        "mse_Q1 = mean_squared_error(y, ypred1)\n",
        "print('The MSE value is:', mse_Q1)"
      ],
      "metadata": {
        "id": "SML-dIQWJP9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **R-Squared**"
      ],
      "metadata": {
        "id": "FpRwjddnM_vW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "r_squared = r2_score(y,p(X))\n",
        "print('The R-squared value is:', r_squared)"
      ],
      "metadata": {
        "id": "Hr3YC3GeNBl0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can see that the accuracy score is greater than  0.99  it means we can use this model to solve polynomial regression, and also mean squared error rate is also low."
      ],
      "metadata": {
        "id": "qwmMKfLrNPbu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.5.4 Common Mistakes**"
      ],
      "metadata": {
        "id": "3UWPAsT4Nxkj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section, we will go over the most common errors that people make when working on a regression problem. We'll go over the top two most common errors."
      ],
      "metadata": {
        "id": "ku9pf-yxOWQ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **3.5.4.1 Underfitting and Overfitting**"
      ],
      "metadata": {
        "id": "ERPAjGKURfwZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This situation where any given model is performing too well on the training data but the performance drops significantly over the test set is called an **overfitting model**."
      ],
      "metadata": {
        "id": "peTaizpPRmHc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "On the other hand, if the model is performing poorly over the test and the train set, then we call that an **underfitting model**. An example of this situation would be building a linear regression model over non-linear data."
      ],
      "metadata": {
        "id": "wB9M3AJ2bN18"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The solution of underfitting is straightforward:\n",
        "1. Increasing the size of the dataset\n",
        "2. Increasing the complexity of the model\n",
        "3. Training the model for more time until it fits.\n",
        "\n",
        "Overfitting solution is a bit trickier because it needs more\n",
        "carefulness:\n",
        "1. Gather more data, of course. However, this solution is not\n",
        "always feasible.\n",
        "2. Use cross-validation. So, let us stop here and know what is\n",
        "meant by cross-validation.\n"
      ],
      "metadata": {
        "id": "S7yUzH5qbn1b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **3.5.4.2 High $R^2$ Score Overinterpreting**"
      ],
      "metadata": {
        "id": "6-p6VRx7cAtH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you remember, we said that a high $R^2$ score means that\n",
        "there is a high correlation between the two variables.\n",
        "However, you need to interpret it carefully, as it usually occurs\n",
        "also when the model is overfitting.\n",
        "\n",
        "Moreover, you need to know what is a high $R^2$ score, as it\n",
        "varies a lot from one domain to another. Therefore, you can\n",
        "get $R^2 =0.6$ for a problem and $R^2 =0.75$ for another problem,\n",
        "and the first one is considered high while the second one is\n",
        "not."
      ],
      "metadata": {
        "id": "RlvJADdYdvGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3.6 Logistic Regression**"
      ],
      "metadata": {
        "id": "hkFEDVg2icA3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A statistical model that uses a logistic function to model a binary dependent variable. A **sigmoid function** is another name for the logistic function, and it is given by:\n",
        "\n",
        "$$F(x)=\\frac{1}{1+e^x}=\\frac{e^x}{e^x+1}$$\n",
        "\n",
        "This function helps the logistic regression model squeeze values between $(-k,k)$ and $(0,1)$. Logistic regression is mostly used for binary classification tasks, but it can also be used for multiclass classification."
      ],
      "metadata": {
        "id": "55K0g6GgxjMm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here the question is, **why are we calling a classification model the Logistic Regression?**"
      ],
      "metadata": {
        "id": "aNRfCuGEyPtu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The reason for this is that logistic regression, like linear regression, begins with a linear equation. However, this equation is made up of log-odds, which are then passed through a sigmoid function, which reduces the linear equation's output to a probability between $0$ and $1$. We can also set a decision boundary and use this probability to perform classification tasks. For example, suppose we are predicting whether it will rain tomorrow or not based on the given dataset, and if the logistic model predicts a probability of 90%, we can confidently state that it will rain tomorrow. On the other hand, if the probability is 10%, we can say that it is not going to rain tomorrow."
      ],
      "metadata": {
        "id": "TG-9gVs4ypHd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.6.1 Maths behind Logistic Regression**"
      ],
      "metadata": {
        "id": "vKSxuzGgznrx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We could begin by assuming that $p(x)$ is a linear function. The problem is that $p$ is the probability that should range from $0$ to $1$, whereas $p(x)$ is an unbounded linear equation. To address this problem, let us assume $log~ p(x)$ is a linear function of $x$ and that we will use **logit** transformation to constrain it to a range of $(0,1)$. As a result, we'll look at $log\\frac{p(x)}{(1-p(x))}$. Then we'll make this function linear:"
      ],
      "metadata": {
        "id": "xSf2BU0T0Pz7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$log\\frac{p(x)}{1-p(x)}=\\alpha+\\beta x$$\n",
        "\n",
        "After solving for $p(x)$:\n",
        "$$p(x)=\\frac{e^{\\alpha+\\beta x}}{e^{\\alpha+\\beta x}+1}~~~~~~~~~{(Sigmoid ~function)}$$\n",
        "\n",
        "To make the logistic regression a linear classifier, we could choose a certain threshold, e.g. $0.5$. Now, the misclassification rate can be minimized if we predict $y=1$ when $p \\geq 0.5$ and $y=0$ when $p<0.5$. Here, $1$ and $0$ are the classes."
      ],
      "metadata": {
        "id": "BaYhsl4v050s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since Logistic regression predicts probabilities, we can fit it using likelihood. Therefore, for each training data point $x$, the predicted class is $y$. Probability of $y$ is either $p$ if $y=1$ or $1-p$ if $y=0$. Now, the likelihood can be written as:\n",
        "\n",
        "$$L(\\alpha,\\beta)=\\prod_{i=1}^np(x_i)^{y_i}(1-p(x_i))^{1-y_i}$$\n",
        "The multiplication can be transformed into a sum by taking the $log$:"
      ],
      "metadata": {
        "id": "5HHQIo3_3Bhk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$l(\\alpha,\\beta)=\\sum_{i=0}^nlog[p(x_i)^{y_i}(1-p(x_i))^{1-y_i}]$$\n",
        "$$=\\sum_{i=0}^n[y_ilog (p(x_i))+(1-y_i)log(1-p(x_i))]$$\n",
        "$$=\\sum_{i=0}^n\\left[y_ilog\\frac{p(x_i)}{1-p(x_i)}+log(1-p(x_i))\\right]$$\n",
        "$$=\\sum_{i=0}^nlog(1-p(x_i))+\\sum_{i=0}^ny_ilog\\frac{p(x_i)}{1-p(x_i)}$$\n",
        "\n",
        "Further, after putting the value of $p(x)$:\n",
        "\n",
        "$$l(\\alpha,\\beta)=\\sum_{i=0}^n-log(1+e^{\\alpha+\\beta x_i})+\\sum_{i=0}^ny_i(\\alpha+\\beta x_i)$$\n",
        "\n",
        "The next step is to take a **maximum** of the above likelihood function."
      ],
      "metadata": {
        "id": "4QrueJ624Cs0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.6.2 Maximum Likelihood Estimation (MLE)**"
      ],
      "metadata": {
        "id": "1N7qnX-z8rvx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A method of estimating the parameters of probability distribution by maximizing a likelihood function, in order to increase the probability of occurring the observed data. We can find *MLE* by differentiating the above equation with respect to different parameters and setting it to be zero."
      ],
      "metadata": {
        "id": "XULUk5fX9Jdg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Types of Logistic Regression:**\n",
        "\n",
        "* *Binary Logistic Regression*: The target variable has only two possible outcomes such as Spam or Not Spam, Cancer or No Cancer. \n",
        "\n",
        "* *Multinomial Logistic Regression*: The target variable has three or more nominal categories such as predicting the type of Wine.\n",
        "\n",
        "* *Ordinal Logistic Regression*: the target variable has three or more ordinal categories such as restaurant or product rating from $1$ to $5$."
      ],
      "metadata": {
        "id": "IHOlep-Yl8fR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.6.3 Logistic Regression Hands-on Project**"
      ],
      "metadata": {
        "id": "ixDHbScWMBFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's build the diabetes prediction model.\n",
        "\n",
        "Here, you are going to predict diabetes using Logistic Regression Classifier.\n",
        "\n",
        "Let's first load the required Pima Indian Diabetes dataset using the pandas' read CSV function. You can download data from the following link: [https://drive.google.com/file/d/1D5TUW1uGZd2O6CbhPaJRVg3N8yNImda_/view?usp=sharing]"
      ],
      "metadata": {
        "id": "pDRn3ZgPM0rq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading Data**"
      ],
      "metadata": {
        "id": "CWtUtgmWnCyh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "col_names = ['pregnant', 'glucose', 'bp', 'skin', 'insulin', 'bmi', 'pedigree', 'age', 'label']\n",
        "pima = pd.read_csv('diabetes.csv', header=None, names=col_names)\n",
        "pima = pima.iloc[1:]\n",
        "pima.head()"
      ],
      "metadata": {
        "id": "ZjuRdp65nKek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Selecting Feature**\n",
        "\n",
        "Here, you need to divide the given columns into two types of variables dependent(or target variable) and independent variable(or feature variables)."
      ],
      "metadata": {
        "id": "DGOAlewyoCps"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#split dataset in features and target variable\n",
        "feature_cols = ['pregnant', 'insulin', 'bmi', 'age','glucose','bp','pedigree']\n",
        "X = pima[feature_cols] # Features\n",
        "y = pima.label # Target variable"
      ],
      "metadata": {
        "id": "36GyhqNTn6IF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Splitting Data**\n",
        "\n",
        "A good strategy for understanding model performance is to divide the dataset into a training set and a test set.\n",
        "\n",
        "Let's split the dataset using the `train_test_split()`. You must supply three parameters: features, target, and test_set size. You can also use random state to select records at random."
      ],
      "metadata": {
        "id": "lLHCtPh6oirm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# split X and y into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size = 0.25)\n",
        "scaler = MinMaxScaler()\n",
        "X_train = pd.DataFrame(scaler.fit_transform(X_train),columns=X_train.columns)\n",
        "X_test = pd.DataFrame(scaler.transform(X_test),columns=X_test.columns)"
      ],
      "metadata": {
        "id": "N3r4tN00o_oo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Dataset is divided into $75:25$ parts in this case. This means that $75\\%$ of the data will be used for model training and $25\\%$ for model testing."
      ],
      "metadata": {
        "id": "oWND0-luqIcj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Development and Prediction**\n",
        "\n",
        "First, import the Logistic Regression module and use the `LogisticRegression()` function to create a Logistic Regression classifier object.\n",
        "\n",
        "Then, fit your model on the train set using `fit()` and perform prediction on the test set using `predict()`."
      ],
      "metadata": {
        "id": "k8Xno6pGqTN9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logreg = LogisticRegression()\n",
        "\n",
        "# fit the model with data\n",
        "mod1 = logreg.fit(X_train,y_train)\n",
        "\n",
        "# test our model\n",
        "pred1=logreg.predict(X_test)"
      ],
      "metadata": {
        "id": "qRV1FTH7viq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_true=y_test, y_pred=pred1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1U1-BoLTvvig",
        "outputId": "01de7d04-2ea1-47e5-8341-1684b2fdee4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7708333333333334"
            ]
          },
          "metadata": {},
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Well, we got a classification rate of 77%, considered as good accuracy."
      ],
      "metadata": {
        "id": "HAgdJKXF0siI"
      }
    }
  ]
}